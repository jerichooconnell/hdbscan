{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.tex\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.tex\n",
    "\n",
    "% Default to the notebook output style\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "% Inherit from the specified cell style.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\\documentclass[11pt]{article}\n",
    "\n",
    "    \n",
    "    \n",
    "    \\usepackage[T1]{fontenc}\n",
    "    % Nicer default font (+ math font) than Computer Modern for most use cases\n",
    "    \\usepackage{mathpazo}\n",
    "\n",
    "    % Basic figure setup, for now with no caption control since it's done\n",
    "    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).\n",
    "    \\usepackage{graphicx}\n",
    "    % We will generate all images so they have a width \\maxwidth. This means\n",
    "    % that they will get their normal width if they fit onto the page, but\n",
    "    % are scaled down if they would overflow the margins.\n",
    "    \\makeatletter\n",
    "    \\def\\maxwidth{\\ifdim\\Gin@nat@width>\\linewidth\\linewidth\n",
    "    \\else\\Gin@nat@width\\fi}\n",
    "    \\makeatother\n",
    "    \\let\\Oldincludegraphics\\includegraphics\n",
    "    % Set max figure width to be 80% of text width, for now hardcoded.\n",
    "    \\renewcommand{\\includegraphics}[1]{\\Oldincludegraphics[width=.8\\maxwidth]{#1}}\n",
    "    % Ensure that by default, figures have no caption (until we provide a\n",
    "    % proper Figure object with a Caption API and a way to capture that\n",
    "    % in the conversion process - todo).\n",
    "    \\usepackage{caption}\n",
    "    \\DeclareCaptionLabelFormat{nolabel}{}\n",
    "    \\captionsetup{labelformat=nolabel}\n",
    "\n",
    "    \\usepackage{adjustbox} % Used to constrain images to a maximum size \n",
    "    \\usepackage{xcolor} % Allow colors to be defined\n",
    "    \\usepackage{enumerate} % Needed for markdown enumerations to work\n",
    "    \\usepackage{geometry} % Used to adjust the document margins\n",
    "    \\usepackage{amsmath} % Equations\n",
    "    \\usepackage{amssymb} % Equations\n",
    "    \\usepackage{textcomp} % defines textquotesingle\n",
    "    % Hack from http://tex.stackexchange.com/a/47451/13684:\n",
    "    \\AtBeginDocument{%\n",
    "        \\def\\PYZsq{\\textquotesingle}% Upright quotes in Pygmentized code\n",
    "    }\n",
    "    \\usepackage{upquote} % Upright quotes for verbatim code\n",
    "    \\usepackage{eurosym} % defines \\euro\n",
    "    \\usepackage[mathletters]{ucs} % Extended unicode (utf-8) support\n",
    "    \\usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document\n",
    "    \\usepackage{fancyvrb} % verbatim replacement that allows latex\n",
    "    \\usepackage{grffile} % extends the file name processing of package graphics \n",
    "                         % to support a larger range \n",
    "    % The hyperref package gives us a pdf with properly built\n",
    "    % internal navigation ('pdf bookmarks' for the table of contents,\n",
    "    % internal cross-reference links, web links for URLs, etc.)\n",
    "    \\usepackage{hyperref}\n",
    "    \\usepackage{longtable} % longtable support required by pandoc >1.10\n",
    "    \\usepackage{booktabs}  % table support for pandoc > 1.12.2\n",
    "    \\usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)\n",
    "    \\usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\\sout)\n",
    "                                % normalem makes italics be italics, not underlines\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    % Colors for the hyperref package\n",
    "    \\definecolor{urlcolor}{rgb}{0,.145,.698}\n",
    "    \\definecolor{linkcolor}{rgb}{.71,0.21,0.01}\n",
    "    \\definecolor{citecolor}{rgb}{.12,.54,.11}\n",
    "\n",
    "    % ANSI colors\n",
    "    \\definecolor{ansi-black}{HTML}{3E424D}\n",
    "    \\definecolor{ansi-black-intense}{HTML}{282C36}\n",
    "    \\definecolor{ansi-red}{HTML}{E75C58}\n",
    "    \\definecolor{ansi-red-intense}{HTML}{B22B31}\n",
    "    \\definecolor{ansi-green}{HTML}{00A250}\n",
    "    \\definecolor{ansi-green-intense}{HTML}{007427}\n",
    "    \\definecolor{ansi-yellow}{HTML}{DDB62B}\n",
    "    \\definecolor{ansi-yellow-intense}{HTML}{B27D12}\n",
    "    \\definecolor{ansi-blue}{HTML}{208FFB}\n",
    "    \\definecolor{ansi-blue-intense}{HTML}{0065CA}\n",
    "    \\definecolor{ansi-magenta}{HTML}{D160C4}\n",
    "    \\definecolor{ansi-magenta-intense}{HTML}{A03196}\n",
    "    \\definecolor{ansi-cyan}{HTML}{60C6C8}\n",
    "    \\definecolor{ansi-cyan-intense}{HTML}{258F8F}\n",
    "    \\definecolor{ansi-white}{HTML}{C5C1B4}\n",
    "    \\definecolor{ansi-white-intense}{HTML}{A1A6B2}\n",
    "\n",
    "    % commands and environments needed by pandoc snippets\n",
    "    % extracted from the output of `pandoc -s`\n",
    "    \\providecommand{\\tightlist}{%\n",
    "      \\setlength{\\itemsep}{0pt}\\setlength{\\parskip}{0pt}}\n",
    "    \\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\\\\{\\}}\n",
    "    % Add ',fontsize=\\small' for more characters per line\n",
    "    \\newenvironment{Shaded}{}{}\n",
    "    \\newcommand{\\KeywordTok}[1]{\\textcolor[rgb]{0.00,0.44,0.13}{\\textbf{{#1}}}}\n",
    "    \\newcommand{\\DataTypeTok}[1]{\\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}\n",
    "    \\newcommand{\\DecValTok}[1]{\\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}\n",
    "    \\newcommand{\\BaseNTok}[1]{\\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}\n",
    "    \\newcommand{\\FloatTok}[1]{\\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}\n",
    "    \\newcommand{\\CharTok}[1]{\\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}\n",
    "    \\newcommand{\\StringTok}[1]{\\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}\n",
    "    \\newcommand{\\CommentTok}[1]{\\textcolor[rgb]{0.38,0.63,0.69}{\\textit{{#1}}}}\n",
    "    \\newcommand{\\OtherTok}[1]{\\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}\n",
    "    \\newcommand{\\AlertTok}[1]{\\textcolor[rgb]{1.00,0.00,0.00}{\\textbf{{#1}}}}\n",
    "    \\newcommand{\\FunctionTok}[1]{\\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}\n",
    "    \\newcommand{\\RegionMarkerTok}[1]{{#1}}\n",
    "    \\newcommand{\\ErrorTok}[1]{\\textcolor[rgb]{1.00,0.00,0.00}{\\textbf{{#1}}}}\n",
    "    \\newcommand{\\NormalTok}[1]{{#1}}\n",
    "    \n",
    "    % Additional commands for more recent versions of Pandoc\n",
    "    \\newcommand{\\ConstantTok}[1]{\\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}\n",
    "    \\newcommand{\\SpecialCharTok}[1]{\\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}\n",
    "    \\newcommand{\\VerbatimStringTok}[1]{\\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}\n",
    "    \\newcommand{\\SpecialStringTok}[1]{\\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}\n",
    "    \\newcommand{\\ImportTok}[1]{{#1}}\n",
    "    \\newcommand{\\DocumentationTok}[1]{\\textcolor[rgb]{0.73,0.13,0.13}{\\textit{{#1}}}}\n",
    "    \\newcommand{\\AnnotationTok}[1]{\\textcolor[rgb]{0.38,0.63,0.69}{\\textbf{\\textit{{#1}}}}}\n",
    "    \\newcommand{\\CommentVarTok}[1]{\\textcolor[rgb]{0.38,0.63,0.69}{\\textbf{\\textit{{#1}}}}}\n",
    "    \\newcommand{\\VariableTok}[1]{\\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}\n",
    "    \\newcommand{\\ControlFlowTok}[1]{\\textcolor[rgb]{0.00,0.44,0.13}{\\textbf{{#1}}}}\n",
    "    \\newcommand{\\OperatorTok}[1]{\\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}\n",
    "    \\newcommand{\\BuiltInTok}[1]{{#1}}\n",
    "    \\newcommand{\\ExtensionTok}[1]{{#1}}\n",
    "    \\newcommand{\\PreprocessorTok}[1]{\\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}\n",
    "    \\newcommand{\\AttributeTok}[1]{\\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}\n",
    "    \\newcommand{\\InformationTok}[1]{\\textcolor[rgb]{0.38,0.63,0.69}{\\textbf{\\textit{{#1}}}}}\n",
    "    \\newcommand{\\WarningTok}[1]{\\textcolor[rgb]{0.38,0.63,0.69}{\\textbf{\\textit{{#1}}}}}\n",
    "    \n",
    "    \n",
    "    % Define a nice break command that doesn't care if a line doesn't already\n",
    "    % exist.\n",
    "    \\def\\br{\\hspace*{\\fill} \\\\* }\n",
    "    % Math Jax compatability definitions\n",
    "    \\def\\gt{>}\n",
    "    \\def\\lt{<}\n",
    "    % Document parameters\n",
    "    \\title{draft\\_for\\_paper}\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    % Pygments definitions\n",
    "    \n",
    "\\makeatletter\n",
    "\\def\\PY@reset{\\let\\PY@it=\\relax \\let\\PY@bf=\\relax%\n",
    "    \\let\\PY@ul=\\relax \\let\\PY@tc=\\relax%\n",
    "    \\let\\PY@bc=\\relax \\let\\PY@ff=\\relax}\n",
    "\\def\\PY@tok#1{\\csname PY@tok@#1\\endcsname}\n",
    "\\def\\PY@toks#1+{\\ifx\\relax#1\\empty\\else%\n",
    "    \\PY@tok{#1}\\expandafter\\PY@toks\\fi}\n",
    "\\def\\PY@do#1{\\PY@bc{\\PY@tc{\\PY@ul{%\n",
    "    \\PY@it{\\PY@bf{\\PY@ff{#1}}}}}}}\n",
    "\\def\\PY#1#2{\\PY@reset\\PY@toks#1+\\relax+\\PY@do{#2}}\n",
    "\n",
    "\\expandafter\\def\\csname PY@tok@w\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.73,0.73,0.73}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@c\\endcsname{\\let\\PY@it=\\textit\\def\\PY@tc##1{\\textcolor[rgb]{0.25,0.50,0.50}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@cp\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.74,0.48,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@k\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.50,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@kp\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.50,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@kt\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.69,0.00,0.25}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@o\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.40,0.40,0.40}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@ow\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.67,0.13,1.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@nb\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.50,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@nf\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.00,1.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@nc\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.00,1.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@nn\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.00,1.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@ne\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.82,0.25,0.23}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@nv\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.10,0.09,0.49}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@no\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.53,0.00,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@nl\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.63,0.63,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@ni\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.60,0.60,0.60}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@na\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.49,0.56,0.16}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@nt\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.50,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@nd\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.67,0.13,1.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@s\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.73,0.13,0.13}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@sd\\endcsname{\\let\\PY@it=\\textit\\def\\PY@tc##1{\\textcolor[rgb]{0.73,0.13,0.13}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@si\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.73,0.40,0.53}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@se\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.73,0.40,0.13}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@sr\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.73,0.40,0.53}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@ss\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.10,0.09,0.49}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@sx\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.50,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@m\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.40,0.40,0.40}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@gh\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.00,0.50}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@gu\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.50,0.00,0.50}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@gd\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.63,0.00,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@gi\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.63,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@gr\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{1.00,0.00,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@ge\\endcsname{\\let\\PY@it=\\textit}\n",
    "\\expandafter\\def\\csname PY@tok@gs\\endcsname{\\let\\PY@bf=\\textbf}\n",
    "\\expandafter\\def\\csname PY@tok@gp\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.00,0.50}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@go\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.53,0.53,0.53}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@gt\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.27,0.87}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@err\\endcsname{\\def\\PY@bc##1{\\setlength{\\fboxsep}{0pt}\\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\\strut ##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@kc\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.50,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@kd\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.50,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@kn\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.50,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@kr\\endcsname{\\let\\PY@bf=\\textbf\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.50,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@bp\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.50,0.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@fm\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.00,0.00,1.00}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@vc\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.10,0.09,0.49}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@vg\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.10,0.09,0.49}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@vi\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.10,0.09,0.49}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@vm\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.10,0.09,0.49}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@sa\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.73,0.13,0.13}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@sb\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.73,0.13,0.13}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@sc\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.73,0.13,0.13}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@dl\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.73,0.13,0.13}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@s2\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.73,0.13,0.13}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@sh\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.73,0.13,0.13}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@s1\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.73,0.13,0.13}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@mb\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.40,0.40,0.40}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@mf\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.40,0.40,0.40}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@mh\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.40,0.40,0.40}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@mi\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.40,0.40,0.40}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@il\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.40,0.40,0.40}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@mo\\endcsname{\\def\\PY@tc##1{\\textcolor[rgb]{0.40,0.40,0.40}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@ch\\endcsname{\\let\\PY@it=\\textit\\def\\PY@tc##1{\\textcolor[rgb]{0.25,0.50,0.50}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@cm\\endcsname{\\let\\PY@it=\\textit\\def\\PY@tc##1{\\textcolor[rgb]{0.25,0.50,0.50}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@cpf\\endcsname{\\let\\PY@it=\\textit\\def\\PY@tc##1{\\textcolor[rgb]{0.25,0.50,0.50}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@c1\\endcsname{\\let\\PY@it=\\textit\\def\\PY@tc##1{\\textcolor[rgb]{0.25,0.50,0.50}{##1}}}\n",
    "\\expandafter\\def\\csname PY@tok@cs\\endcsname{\\let\\PY@it=\\textit\\def\\PY@tc##1{\\textcolor[rgb]{0.25,0.50,0.50}{##1}}}\n",
    "\n",
    "\\def\\PYZbs{\\char`\\\\}\n",
    "\\def\\PYZus{\\char`\\_}\n",
    "\\def\\PYZob{\\char`\\{}\n",
    "\\def\\PYZcb{\\char`\\}}\n",
    "\\def\\PYZca{\\char`\\^}\n",
    "\\def\\PYZam{\\char`\\&}\n",
    "\\def\\PYZlt{\\char`\\<}\n",
    "\\def\\PYZgt{\\char`\\>}\n",
    "\\def\\PYZsh{\\char`\\#}\n",
    "\\def\\PYZpc{\\char`\\%}\n",
    "\\def\\PYZdl{\\char`\\$}\n",
    "\\def\\PYZhy{\\char`\\-}\n",
    "\\def\\PYZsq{\\char`\\'}\n",
    "\\def\\PYZdq{\\char`\\\"}\n",
    "\\def\\PYZti{\\char`\\~}\n",
    "% for compatibility with earlier versions\n",
    "\\def\\PYZat{@}\n",
    "\\def\\PYZlb{[}\n",
    "\\def\\PYZrb{]}\n",
    "\\makeatother\n",
    "\n",
    "\n",
    "    % Exact colors from NB\n",
    "    \\definecolor{incolor}{rgb}{0.0, 0.0, 0.5}\n",
    "    \\definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    % Prevent overflowing lines due to hard-to-break entities\n",
    "    \\sloppy \n",
    "    % Setup hyperref package\n",
    "    \\hypersetup{\n",
    "      breaklinks=true,  % so long urls are correctly broken across lines\n",
    "      colorlinks=true,\n",
    "      urlcolor=urlcolor,\n",
    "      linkcolor=linkcolor,\n",
    "      citecolor=citecolor,\n",
    "      }\n",
    "    % Slightly bigger margins than the latex defaults\n",
    "    \n",
    "    \\geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}\n",
    "    \n",
    "    \n",
    "\n",
    "    \\begin{document}\n",
    "    \n",
    "    \n",
    "    \\maketitle\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}69}]:} \\PY{o}{\\PYZpc{}}\\PY{k}{pylab} inline\n",
    "         \\PY{o}{\\PYZpc{}}\\PY{k}{load\\PYZus{}ext} autoreload\n",
    "         \\PY{o}{\\PYZpc{}}\\PY{k}{autoreload} 2\n",
    "         \\PY{n}{paper\\PYZus{}dir} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{\\PYZsq{}}\n",
    "         \\PY{n}{section} \\PY{o}{=} \\PY{l+m+mi}{0}\n",
    "         \\PY{n}{subsection} \\PY{o}{=} \\PY{l+m+mi}{0}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "Populating the interactive namespace from numpy and matplotlib\n",
    "The autoreload extension is already loaded. To reload it, use:\n",
    "  \\%reload\\_ext autoreload\n",
    "\n",
    "    \\end{Verbatim}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}3}]:} \\PY{k+kn}{from} \\PY{n+nn}{clustering\\PYZus{}comparison} \\PY{k}{import} \\PY{o}{*}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}70}]:} \\PY{n}{fname} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+s1}{.txt}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{n}{section}\\PY{p}{,}\\PY{n}{subsection}\\PY{p}{)}\n",
    "         \\PY{n}{subsection} \\PY{o}{+}\\PY{o}{=} \\PY{l+m+mi}{1}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}73}]:} \\PY{o}{\\PYZpc{}\\PYZpc{}writefile} \\PYZdl{}fname\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "Writing 00.txt\n",
    "\n",
    "    \\end{Verbatim}\n",
    "\n",
    "    \\hypertarget{draft-for-paper}{%\n",
    "\\section{Draft for Paper}\\label{draft-for-paper}}\n",
    "\n",
    "    \\hypertarget{introduction}{%\n",
    "\\subsection{Introduction}\\label{introduction}}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor} }]:} \\PY{n}{fname} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+s1}{.txt}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{n}{section}\\PY{p}{,}\\PY{n}{subsection}\\PY{p}{)}\n",
    "        \\PY{n}{subsection} \\PY{o}{+}\\PY{o}{=} \\PY{l+m+mi}{1}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    Spectral imaging remains an unexplored imaging modality for multiple\n",
    "reasons. Firstly the price of spectral detectors is a large barrier to\n",
    "the clinical implementation. Secondly the applications where spectral\n",
    "imaging outdoes single energy and dual energy imaging are not well\n",
    "defined. Although there has been much interest in spectral CT in\n",
    "medicine it is often seen to have only small benefits as compared with\n",
    "dual energy CT in the same application.\n",
    "\n",
    "In this work we examine spectral imaging as compared to dual and single\n",
    "imaging in the application of segmentation. A comparison is made of the\n",
    "performance of unsupervised segmentation algorithms is performed on\n",
    "experimental images acquired using a Redlen (redlen industries \\ldots{})\n",
    "spectral detector on a phantom composed of a variety of materials as\n",
    "well as images aquired of these same materials embedded in chicken\n",
    "breast.\n",
    "\n",
    "    \\hypertarget{methods}{%\n",
    "\\subsection{Methods}\\label{methods}}\n",
    "\n",
    "    \\hypertarget{data-aquisition}{%\n",
    "\\subsubsection{Data aquisition}\\label{data-aquisition}}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor} }]:} \\PY{n}{section} \\PY{o}{+}\\PY{o}{=} \\PY{l+m+mi}{1}\n",
    "        \\PY{n}{subsection} \\PY{o}{=} \\PY{l+m+mi}{0}\n",
    "        \\PY{n}{fname} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+s1}{.txt}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{n}{section}\\PY{p}{,}\\PY{n}{subsection}\\PY{p}{)}\n",
    "        \\PY{n}{subsection} \\PY{o}{+}\\PY{o}{=} \\PY{l+m+mi}{1}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    X-ray scans were performed on a PMMA phantom with 5 contaminates (steel,\n",
    "glass, plastic, polypropylene, and PFTE) as well as chicken flesh with\n",
    "various contaminates (bone, cartilage, fat, plastic, wood, glass, rock,\n",
    "steel, and aluminum).\n",
    "\n",
    "Data was acquired using a CZT detector with a 8\\$\\times\\$12 mm imaging\n",
    "array from Redlen Technologies. The 330 \\(\\mu\\)m pitch high-flux CZT\n",
    "detector is 2mm thick and is able to operate at 250\n",
    "\\(\\frac{Mcps}{mm^2}\\) without any signs of polarization. Travel Heat\n",
    "Method (THM) was adopted by Redlen Technologies when growing the CZT\n",
    "crystals used in the detector. These crystals were placed in a sensor\n",
    "that is connected to a photon counting ASIC which operates at rates of\n",
    "up to 62.5 \\(\\frac{Mcps}{channel}\\). This ASIC communicates with an\n",
    "external PC though LVDS I/Os via a programmable FPGA. The energies of\n",
    "photons incident with the detector are sorted into six energy bins by\n",
    "the ASIC. In the case of this experiment the energy bins were set to\n",
    "16-33 keV, 33-41 keV, 41-50 keV, 50-90 keV, 90-120 keV, \\&\n",
    "120\\textless{} keV.\n",
    "\n",
    "The detector and X-ray source were both mounted on vertical and\n",
    "horizontal linear motion stages from Newport Corporations. These stages\n",
    "were oriented perpendicular to each other to allow for easy navigation\n",
    "while imaging the phantom, which was mounted between these two stages.\n",
    "The X-ray source used was a module XRS-160 from Comet Technologies.\n",
    "\n",
    "The PMMA phantom block as imaged in figure (1.C) was placed on the stage\n",
    "and the 3 smallest contaminates of each material were imaged. To image\n",
    "these contaminates each at different heights, the CZT detector and X-ray\n",
    "source were moved vertically in a uniform manner allowing for each\n",
    "material to be centered without any motion of the phantom block itself.\n",
    "Following the first round of data acquisitions a second block of 18mm\n",
    "PMMA was placed in front of the phantom block and images were acquired\n",
    "to determine the depth at which each contaminate could be visualized.\n",
    "\n",
    "In the case of the chicken flesh, each contaminate was able to fit in a\n",
    "phantom holder alongside the chicken. This block was placed on the stage\n",
    "and was able to be imaged in one scan per contaminate.\n",
    "\n",
    "Air scans were completed for each data acquisition and could then be\n",
    "processed using MATLAB (The Mathworks, Natick, MA) for image\n",
    "reconstruction and CNR calculations for each contaminate. During all\n",
    "scans the X-ray tube was using a cone beam operating at 1mA, 120 kV,\n",
    "with a 1mm focal spot.\n",
    "\n",
    "    \\hypertarget{data-analysis}{%\n",
    "\\subsubsection{Data Analysis}\\label{data-analysis}}\n",
    "\n",
    "    The main steps required to analyze hyperspectral images include\n",
    "pre-processing of data, dimensionality reduction, enhancement of\n",
    "spectral responses, and component detection or classification (Mahesh et\n",
    "al., 2015). Using this as an analog for spectral imaging similar methods\n",
    "are applied in this study with the exception of enhancement of spectral\n",
    "response as the modelling the spectral response of the CZT detector is\n",
    "beyond the scope of this study.\n",
    "\n",
    "    \\hypertarget{pre-processing-of-data}{%\n",
    "\\paragraph{Pre-processing of Data}\\label{pre-processing-of-data}}\n",
    "\n",
    "    After data aquisition, data pre-processing was performed using\n",
    "MATLAB\\_R2017b (The MathWorks, Natick, USA). The images were first\n",
    "cropped to remove the highly non-uniform edge pixels in some parts of\n",
    "the detector. Dead pixels were then found manually and replaced with NaN\n",
    "values in the image. These NaN values were then interpolated to be the\n",
    "average of the surrounding eight pixels. The images were then smoothed\n",
    "using a two dimensional gaussian filter with a standard deviation of 0.5\n",
    "in an effort to reduce the noise in the image.\n",
    "\n",
    "    \\hypertarget{dimensional-reduction-methods}{%\n",
    "\\subsubsection{Dimensional Reduction\n",
    "Methods}\\label{dimensional-reduction-methods}}\n",
    "\n",
    "    \\hypertarget{principle-component-analysis}{%\n",
    "\\paragraph{Principle Component\n",
    "Analysis}\\label{principle-component-analysis}}\n",
    "\n",
    "    Dimensional reduction methods were applied in this work to increase\n",
    "class seperation and reduce noise in the data, methods were implemented\n",
    "in Python using sci-kit learn. Data reduction methods employed in this\n",
    "study were Principle Component Analysis (PCA). PCA does an eigenvalue\n",
    "decomposition of the covariance matrix, sorting the eigenvectors in\n",
    "terms of the magnitude of their eigenvalue one finds the directions of\n",
    "highest variance in the data. The data is then projected into a lower\n",
    "dimensional orhtogonal space defined by the eigenvectors with the most\n",
    "variance, in this case the data was reduced to two dimensions. This\n",
    "method results in a loss of information, however this loss of\n",
    "information is usually relatively small and ideally the discarded\n",
    "dimensions in the data amount to noise in the data. PCA can be seen in\n",
    "fig \\ref{}. PCA is fast, linear and sees application in many domains.\n",
    "\n",
    "    \\hypertarget{independant-component-analysis}{%\n",
    "\\paragraph{Independant Component\n",
    "Analysis}\\label{independant-component-analysis}}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor} }]:} \\PY{n}{fname} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+s1}{.txt}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{n}{section}\\PY{p}{,}\\PY{n}{subsection}\\PY{p}{)}\n",
    "        \\PY{n}{subsection} \\PY{o}{+}\\PY{o}{=} \\PY{l+m+mi}{1}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    Typically not used for dimension reduction but for blind source\n",
    "seperation, independant component analysis (ICA) is used for seperating\n",
    "a mixed signal into its constituent signals and is often used in audio\n",
    "analysis but has seen use in hyperspectral imaging \\ref{}. Using ICA we\n",
    "frame the segmentation of the two images as a decomposition in which the\n",
    "image is a weighted addition of two signals, the background material\n",
    "(PMMA) and the contaminant. ICA aims to find the maximum\n",
    "\n",
    "The components \\(x_i\\) of the images with 5 bins\n",
    "\\(\\boldsymbol{x}=(x_1,\\ldots,x_5)^T\\) are seen to be a sum of the\n",
    "independent components \\(s_k\\), \\(k=1,\\ldots,5\\):\n",
    "\n",
    "\\(x_i = a_{i,1} s_1 + \\cdots + a_{i,k} s_k + \\cdots + a_{i,5} s_5\\)\n",
    "\n",
    "where \\(a_{i,k}\\) are the mixing weights.\n",
    "\n",
    "Or in matrix form as\n",
    "\\(\\boldsymbol{x}=\\sum_{k=1}^{5} s_k \\boldsymbol{a}_k\\), where our image\n",
    "vectors \\(\\boldsymbol{x}\\) are represented by the basis vectors\n",
    "\\(\\boldsymbol{a}_k=(\\boldsymbol{a}_{1,k},\\ldots,\\boldsymbol{a}_{m,k})^T\\).\n",
    "The basis vectors \\(\\boldsymbol{a}_k\\) form the columns of the mixing\n",
    "matrix \\(\\boldsymbol{A}=(\\boldsymbol{a}_1,\\ldots,\\boldsymbol{a}_5)\\).\n",
    "\n",
    "Putting all this together we have the matrix equation\n",
    "\\(\\boldsymbol{x}=\\boldsymbol{A} \\boldsymbol{s}\\), where\n",
    "\\(\\boldsymbol{s}=(s_1,\\ldots,s_5)^T\\).\n",
    "\n",
    "Given our images \\(\\boldsymbol{x}_1,\\ldots,\\boldsymbol{x}_N\\) of the\n",
    "random vector \\(\\boldsymbol{x}\\), the task is to estimate both the\n",
    "mixing matrix \\(\\boldsymbol{A}\\) and the sources \\(\\boldsymbol{s}\\).\n",
    "This is done by adaptively calculating the \\(\\boldsymbol{w}\\) vectors\n",
    "and setting up a cost function which maximizes the non-gaussianity of\n",
    "the calculated \\(s_k = \\boldsymbol{w}^T \\boldsymbol{x}\\).\n",
    "\n",
    "In this paper we use the maximum likelihood estimate (MLE) algorithm for\n",
    "finding the unmixing matrix \\(W\\)\n",
    "\n",
    "''`{[}{[}Maximum likelihood{]}{]} estimation (MLE)''' is a standard\n",
    "statistical tool for finding parameter values (e.g.~the unmixing matrix\n",
    "\\(\\mathbf{W}\\)) that provide the best fit of some data (e.g., the\n",
    "extracted signals \\(y\\)) to a given a model (e.g., the assumed joint\n",
    "probability density function (pdf) \\(p_s\\) of source signals).\n",
    "\n",
    "The '`'ML''' ``model'' includes a specification of a pdf, which in this\n",
    "case is the pdf \\(p_s\\) of the unknown source signals \\(s\\). Using '`'ML\n",
    "ICA''', the objective is to find an unmixing matrix that yields\n",
    "extracted signals \\(y = \\mathbf{W}x\\) with a joint pdf as similar as\n",
    "possible to the joint pdf \\(p_s\\) of the unknown source signals \\(s\\).\n",
    "\n",
    "'`'MLE''' is thus based on the assumption that if the model pdf \\(p_s\\)\n",
    "and the model parameters \\(\\mathbf{A}\\) are correct then a high\n",
    "probability should be obtained for the data \\(x\\) that were actually\n",
    "observed. Conversely, if \\(\\mathbf{A}\\) is far from the correct\n",
    "parameter values then a low probability of the observed data would be\n",
    "expected.\n",
    "\n",
    "Using '`'MLE''`, we call the probability of the observed data for a\n",
    "given set of model parameter values (e.g., a pdf \\(p_s\\) and a matrix\n",
    "\\(\\mathbf{A}\\)) the'`likelihood'' of the model parameter values given\n",
    "the observed data.\n",
    "\n",
    "We define a `'likelihood'' function \\(\\mathbf{L(W)}\\) of \\(\\mathbf{W}\\):\n",
    "\n",
    "\\$\\mathbf{ L(W)} = p\\_s\n",
    "(\\mathbf{W}x)\\textbar{}\\det \\mathbf{W}\\textbar{}. \\$\n",
    "\n",
    "This equals to the probability density at \\(x\\), since\n",
    "\\(s = \\mathbf{W}x\\).\n",
    "\n",
    "Thus, if we wish to find a \\(\\mathbf{W}\\) that is most likely to have\n",
    "generated the observed mixtures \\(x\\) from the unknown source signals\n",
    "\\(s\\) with pdf \\(p_s\\) then we need only find that \\(\\mathbf{W}\\) which\n",
    "maximizes the `'likelihood'' \\(\\mathbf{L(W)}\\). The unmixing matrix that\n",
    "maximizes equation is known as the '`'MLE''' of the optimal unmixing\n",
    "matrix.\n",
    "\n",
    "It is common practice to use the log `'likelihood'`, because this is\n",
    "easier to evaluate. As the logarithm is a monotonic function, the\n",
    "\\(\\mathbf{W}\\) that maximizes the function \\(\\mathbf{L(W)}\\) also\n",
    "maximizes its logarithm \\(\\ln \\mathbf{L(W)}\\). This allows us to take\n",
    "the logarithm of equation above, which yields the log'`likelihood''\n",
    "function\n",
    "\n",
    "\\(\\ln \\mathbf{L(W)} =\\sum_{i}\\sum_{t} \\ln p_s(w^T_ix_t) + N\\ln|\\det \\mathbf{W}|\\)\n",
    "\n",
    "If we substitute a commonly used high-{[}{[}Kurtosis{]}{]} model pdf for\n",
    "the source signals \\(p_s = (1-\\tanh(s)^2)\\) then we have\n",
    "\n",
    "\\(\\ln \\mathbf{L(W)} ={1 \\over N}\\sum_{i}^{M} \\sum_{t}^{N}\\ln(1-\\tanh(w^T_i x_t )^2) + \\ln |\\det \\mathbf{W}|\\)\n",
    "\n",
    "This matrix \\(\\mathbf{W}\\) that maximizes this function is the MLE.\n",
    "\n",
    "    \\hypertarget{non-negative-matrix-factorization}{%\n",
    "\\paragraph{Non-negative Matrix\n",
    "Factorization}\\label{non-negative-matrix-factorization}}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor} }]:} \\PY{n}{fname} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+s1}{.txt}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{n}{section}\\PY{p}{,}\\PY{n}{subsection}\\PY{p}{)}\n",
    "        \\PY{n}{subsection} \\PY{o}{+}\\PY{o}{=} \\PY{l+m+mi}{1}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    Let matrix \\(V\\) be the product of the matrices \\(W\\) and \\(H\\),\n",
    ":\\(\\mathbf{V} = \\mathbf{W} \\mathbf{H} \\,.\\)\n",
    "\n",
    "Matrix multiplication can be implemented as computing the column vectors\n",
    "of \\(V\\) as linear combinations of the column vectors in \\(W\\) using\n",
    "coefficients supplied by columns of \\(H\\). That is, each column of \\(V\\)\n",
    "can be computed as follows:\n",
    ":\\(\\mathbf{v}_i = \\mathbf{W} \\mathbf{h}_{i} \\,,\\)\n",
    "\n",
    "where \\(\\mathbf{v}_i\\) is the \\(i\\)-th column vector of the product\n",
    "matrix \\(V\\) and \\(\\mathbf{h}_{i}\\) is the \\(i\\)-th column vector of the\n",
    "matrix \\(H\\).\n",
    "\n",
    "When multiplying matrices, the dimensions of the factor matrices may be\n",
    "significantly lower than those of the product matrix and it is this\n",
    "property that forms the basis of NMF. NMF generates factors with\n",
    "significantly reduced dimensions compared to the original matrix. For\n",
    "example, if \\(V\\) is an \\(m × n\\) matrix, \\(W\\) is an \\(m × p\\) matrix,\n",
    "and \\(H\\) is a \\(p × n\\) matrix then \\(p\\) can be significantly less\n",
    "than both \\(m\\) and \\(n\\).\n",
    "\n",
    "Here is an example based on a text-mining application: * Let the input\n",
    "matrix (the matrix to be factored) be \\(V\\) with 10000 rows and 500\n",
    "columns where words are in rows and documents are in columns. That is,\n",
    "we have 500 documents indexed by 10000 words. It follows that a column\n",
    "vector \\(v\\) in \\(V\\) represents a document. * Assume we ask the\n",
    "algorithm to find 10 features in order to generate a `'features matrix''\n",
    "\\(W\\) with 10000 rows and 10 columns and a `'coefficients matrix'' \\(H\\)\n",
    "with 10 rows and 500 columns. * The product of \\(W\\) and \\(H\\) is a\n",
    "matrix with 10000 rows and 500 columns, the same shape as the input\n",
    "matrix \\(V\\) and, if the factorization worked, it is a reasonable\n",
    "approximation to the input matrix \\(V\\). * From the treatment of matrix\n",
    "multiplication above it follows that each column in the product matrix\n",
    "\\(WH\\) is a linear combination of the 10 column vectors in the features\n",
    "matrix \\(W\\) with coefficients supplied by the coefficients matrix\n",
    "\\(H\\).\n",
    "\n",
    "This last point is the basis of NMF because we can consider each\n",
    "original document in our example as being built from a small set of\n",
    "hidden features. NMF generates these features.\n",
    "\n",
    "It is useful to think of each feature (column vector) in the features\n",
    "matrix \\(W\\) as a document archetype comprising a set of words where\n",
    "each word's cell value defines the word's rank in the feature: The\n",
    "higher a word's cell value the higher the word's rank in the feature. A\n",
    "column in the coefficients matrix \\(H\\) represents an original document\n",
    "with a cell value defining the document's rank for a feature. We can now\n",
    "reconstruct a document (column vector) from our input matrix by a linear\n",
    "combination of our features (column vectors in \\(W\\)) where each feature\n",
    "is weighted by the feature's cell value from the document's column in\n",
    "\\(H\\).\n",
    "\n",
    "== Clustering property == NMF has an inherent clustering property, i.e.,\n",
    "it automatically clusters the columns of input data \\$\\mathbf{V} =\n",
    "(v\\_1, \\cdots, v\\_n) \\$.\n",
    "\n",
    "More specifically, the approximation of \\(\\mathbf{V}\\) by\n",
    "\\(\\mathbf{V} \\simeq \\mathbf{W}\\mathbf{H}\\) is achieved by minimizing the\n",
    "error function\n",
    "\n",
    "\\$ \\min\\_\\{W,H\\} \\textbar{}\\textbar{} V - WH \\textbar{}\\textbar{}\\_F,\\$\n",
    "subject to \\(W \\geq 0, H \\geq 0.\\)\n",
    "\n",
    "Furthermore, the computed \\$ H \\$ gives the cluster membership, i.e., if\n",
    "\\$\\mathbf{H}\\emph{\\{kj\\} \\textgreater{} \\mathbf{H}}\\{ij\\} \\$ for all i ≠\n",
    "k, this suggests that the input data \\$ v\\_j \\$ belongs to \\(k^{th}\\)\n",
    "cluster. The computed \\(W\\) gives the cluster centroids, i.e., the\n",
    "\\(k^{th}\\) column gives the cluster centroid of \\(k^{th}\\) cluster. This\n",
    "centroid's representation can be significantly enhanced by convex NMF.\n",
    "\n",
    "When the orthogonality \\$ H H\\^{}T = I \\$ is not explicitly imposed, the\n",
    "orthogonality holds to a large extent, and the clustering property holds\n",
    "too. Clustering is the main objective of most {[}{[}data mining{]}{]}\n",
    "applications of NMF.\\{\\{citation needed\\textbar{}date=April 2015\\}\\}\n",
    "\n",
    "When the error function to be used is {[}{[}Kullback--Leibler\n",
    "divergence{]}{]}, NMF is identical to the {[}{[}Probabilistic latent\n",
    "semantic analysis{]}{]}, a popular document clustering method.C Ding, T\n",
    "Li, W Peng,\n",
    "{[}http://users.cis.fiu.edu/\\textasciitilde{}taoli/pub/NMFpLSIequiv.pdf\n",
    "\" On the equivalence between non-negative matrix factorization and\n",
    "probabilistic latent semantic indexing\"{]} Computational Statistics \\&\n",
    "Data Analysis 52, 3913-3927\n",
    "\n",
    "    \\hypertarget{nmf-plot}{%\n",
    "\\subsection{NMF plot}\\label{nmf-plot}}\n",
    "\n",
    "    \\hypertarget{ica-plot}{%\n",
    "\\subsection{ICA plot}\\label{ica-plot}}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}10}]:} \\PY{n}{vs1} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{mode} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{all}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{cinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{,}\\PY{n}{red}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{nmf}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_27_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_27_1.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor} }]:} \\PY{o}{\\PYZpc{}}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}11}]:} \\PY{n}{vs1} \\PY{o}{=} \\PY{n}{np}\\PY{o}{.}\\PY{n}{zeros}\\PY{p}{(}\\PY{p}{[}\\PY{l+m+mi}{100}\\PY{p}{,}\\PY{l+m+mi}{100}\\PY{p}{]}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}6}]:} \\PY{n}{vs1} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{mode} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{all}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{cinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{,}\\PY{n}{red}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{ica}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_30_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\hypertarget{nmf-plot}{%\n",
    "\\subsection{NMF plot}\\label{nmf-plot}}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}7}]:} \\PY{n}{vs1} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{cinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{9}\\PY{p}{]}\\PY{p}{,}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{de}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{c+c1}{\\PYZsh{},red=\\PYZsq{}nmf\\PYZsq{})}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_32_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\hypertarget{clustering-methods}{%\n",
    "\\subsection{Clustering Methods}\\label{clustering-methods}}\n",
    "\n",
    "    \\hypertarget{k-means}{%\n",
    "\\subsubsection{K-means}\\label{k-means}}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor} }]:} \\PY{n}{fname} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+s1}{.txt}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{n}{section}\\PY{p}{,}\\PY{n}{subsection}\\PY{p}{)}\n",
    "        \\PY{n}{subsection} \\PY{o}{+}\\PY{o}{=} \\PY{l+m+mi}{1}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    The first clustering method implemented was k-means clustering. K-means\n",
    "was implemented using the k-means++ algorithm of (???). K-means was fit\n",
    "using a value for the number of clusters \\(k\\) defined through the use\n",
    "of silhouette analysis. Different distance metrics were used, however\n",
    "none of the distance metrics tried improved performance over the squared\n",
    "euclidean distance, thus squared euclidean distance was used as the\n",
    "metric.\n",
    "\n",
    "about k-means:\n",
    "\n",
    "``K-Means is the `go-to' clustering algorithm for many simply because it\n",
    "is fast, easy to understand, and available everywhere (there's an\n",
    "implementation in almost any statistical or machine learning tool you\n",
    "care to use). K-Means has a few problems however. The first is that it\n",
    "isn't a clustering algorithm, it is a partitioning algorithm. That is to\n",
    "say K-means doesn't `find clusters' it partitions your dataset into as\n",
    "many (assumed to be globular) chunks as you ask for by attempting to\n",
    "minimize intra-partition distances. That leads to the second problem:\n",
    "you need to specify exactly how many clusters you expect. If you know a\n",
    "lot about your data then that is something you might expect to know. If,\n",
    "on the other hand, you are simply exploring a new dataset then `number\n",
    "of clusters' is a hard parameter to have any good intuition for. The\n",
    "usually proposed solution is to run K-Means for many different `number\n",
    "of clusters' values and score each clustering with some `cluster\n",
    "goodness' measure (usually a variation on intra-cluster vs inter-cluster\n",
    "distances) and attempt to find an `elbow'. If you've ever done this in\n",
    "practice you know that finding said elbow is usually not so easy, nor\n",
    "does it necessarily correlate as well with the actual `natural' number\n",
    "of clusters as you might like. Finally K-Means is also dependent upon\n",
    "initialization; give it multiple different random starts and you can get\n",
    "multiple different clusterings. This does not engender much confidence\n",
    "in any individual clustering that may result.''\n",
    "\n",
    "    \\begin{longtable}[]{@{}lllll@{}}\n",
    "\\toprule\n",
    "\\begin{minipage}[b]{0.25\\columnwidth}\\raggedright\n",
    "Method name\\strut\n",
    "\\end{minipage} & \\begin{minipage}[b]{0.15\\columnwidth}\\raggedright\n",
    "Parameters\\strut\n",
    "\\end{minipage} & \\begin{minipage}[b]{0.13\\columnwidth}\\raggedright\n",
    "Scalability\\strut\n",
    "\\end{minipage} & \\begin{minipage}[b]{0.20\\columnwidth}\\raggedright\n",
    "Usecase\\strut\n",
    "\\end{minipage} & \\begin{minipage}[b]{0.12\\columnwidth}\\raggedright\n",
    "Geometry (metric used)\\strut\n",
    "\\end{minipage}\\tabularnewline\n",
    "\\midrule\n",
    "\\endhead\n",
    "\\begin{minipage}[t]{0.25\\columnwidth}\\raggedright\n",
    "{K-Means \\textless{}k\\_means\\textgreater{}}\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.15\\columnwidth}\\raggedright\n",
    "number of clusters\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.13\\columnwidth}\\raggedright\n",
    "Very large \\texttt{n\\_samples}, medium \\texttt{n\\_clusters} with\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.20\\columnwidth}\\raggedright\n",
    "General-purpose, even cluster size, flat geometry, not too many\n",
    "clusters\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.12\\columnwidth}\\raggedright\n",
    "Distances between points\\strut\n",
    "\\end{minipage}\\tabularnewline\n",
    "\\begin{minipage}[t]{0.25\\columnwidth}\\raggedright\n",
    "{Affinity propagation\n",
    "\\textless{}affinity\\_propagation\\textgreater{}}\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.15\\columnwidth}\\raggedright\n",
    "damping, sample preference\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.13\\columnwidth}\\raggedright\n",
    "Not scalable with n\\_samples\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.20\\columnwidth}\\raggedright\n",
    "Many clusters, uneven cluster size, non-flat geometry\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.12\\columnwidth}\\raggedright\n",
    "Graph distance (e.g.~nearest-neighbor graph)\\strut\n",
    "\\end{minipage}\\tabularnewline\n",
    "\\begin{minipage}[t]{0.25\\columnwidth}\\raggedright\n",
    "{Mean-shift \\textless{}mean\\_shift\\textgreater{}}\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.15\\columnwidth}\\raggedright\n",
    "bandwidth\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.13\\columnwidth}\\raggedright\n",
    "Not scalable with \\texttt{n\\_samples}\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.20\\columnwidth}\\raggedright\n",
    "Many clusters, uneven cluster size, non-flat geometry\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.12\\columnwidth}\\raggedright\n",
    "Distances between points\\strut\n",
    "\\end{minipage}\\tabularnewline\n",
    "\\begin{minipage}[t]{0.25\\columnwidth}\\raggedright\n",
    "{Spectral clustering\n",
    "\\textless{}spectral\\_clustering\\textgreater{}}\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.15\\columnwidth}\\raggedright\n",
    "number of clusters\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.13\\columnwidth}\\raggedright\n",
    "Medium \\texttt{n\\_samples}, small \\texttt{n\\_clusters}\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.20\\columnwidth}\\raggedright\n",
    "Few clusters, even cluster size, non-flat geometry\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.12\\columnwidth}\\raggedright\n",
    "Graph distance (e.g.~nearest-neighbor graph)\\strut\n",
    "\\end{minipage}\\tabularnewline\n",
    "\\begin{minipage}[t]{0.25\\columnwidth}\\raggedright\n",
    "{Ward hierarchical clustering\n",
    "\\textless{}hierarchical\\_clustering\\textgreater{}}\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.15\\columnwidth}\\raggedright\n",
    "number of clusters\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.13\\columnwidth}\\raggedright\n",
    "Large \\texttt{n\\_samples} and \\texttt{n\\_clusters}\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.20\\columnwidth}\\raggedright\n",
    "Many clusters, possibly connectivity constraints\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.12\\columnwidth}\\raggedright\n",
    "Distances between points\\strut\n",
    "\\end{minipage}\\tabularnewline\n",
    "\\begin{minipage}[t]{0.25\\columnwidth}\\raggedright\n",
    "{Agglomerative clustering\n",
    "\\textless{}hierarchical\\_clustering\\textgreater{}}\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.15\\columnwidth}\\raggedright\n",
    "number of clusters, linkage type, distance\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.13\\columnwidth}\\raggedright\n",
    "Large \\texttt{n\\_samples} and \\texttt{n\\_clusters}\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.20\\columnwidth}\\raggedright\n",
    "Many clusters, possibly connectivity constraints, non Euclidean\n",
    "distances\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.12\\columnwidth}\\raggedright\n",
    "Any pairwise distance\\strut\n",
    "\\end{minipage}\\tabularnewline\n",
    "\\begin{minipage}[t]{0.25\\columnwidth}\\raggedright\n",
    "{hDBSCAN \\textless{}dbscan\\textgreater{}}\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.15\\columnwidth}\\raggedright\n",
    "neighborhood size\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.13\\columnwidth}\\raggedright\n",
    "Very large \\texttt{n\\_samples}, medium \\texttt{n\\_clusters}\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.20\\columnwidth}\\raggedright\n",
    "Non-flat geometry, uneven cluster sizes\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.12\\columnwidth}\\raggedright\n",
    "Distances between nearest points\\strut\n",
    "\\end{minipage}\\tabularnewline\n",
    "\\begin{minipage}[t]{0.25\\columnwidth}\\raggedright\n",
    "{Gaussian mixtures \\textless{}mixture\\textgreater{}}\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.15\\columnwidth}\\raggedright\n",
    "many\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.13\\columnwidth}\\raggedright\n",
    "Not scalable\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.20\\columnwidth}\\raggedright\n",
    "Flat geometry, good for density estimation\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.12\\columnwidth}\\raggedright\n",
    "Mahalanobis distances to centers\\strut\n",
    "\\end{minipage}\\tabularnewline\n",
    "\\begin{minipage}[t]{0.25\\columnwidth}\\raggedright\n",
    "{Birch}\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.15\\columnwidth}\\raggedright\n",
    "branching factor, threshold, optional global clusterer.\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.13\\columnwidth}\\raggedright\n",
    "Large \\texttt{n\\_clusters} and \\texttt{n\\_samples}\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.20\\columnwidth}\\raggedright\n",
    "Large dataset, outlier removal, data reduction.\\strut\n",
    "\\end{minipage} & \\begin{minipage}[t]{0.12\\columnwidth}\\raggedright\n",
    "Euclidean distance between points\\strut\n",
    "\\end{minipage}\\tabularnewline\n",
    "\\bottomrule\n",
    "\\end{longtable}\n",
    "\n",
    "    \\hypertarget{mean-shift}{%\n",
    "\\subsubsection{Mean Shift}\\label{mean-shift}}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor} }]:} \\PY{n}{fname} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+s1}{.txt}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{n}{section}\\PY{p}{,}\\PY{n}{subsection}\\PY{p}{)}\n",
    "        \\PY{n}{subsection} \\PY{o}{+}\\PY{o}{=} \\PY{l+m+mi}{1}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    ``Mean shift is another option if you don't want to have to specify the\n",
    "number of clusters. It is centroid based, like K-Means and affinity\n",
    "propagation, but can return clusters instead of a partition. The\n",
    "underlying idea of the Mean Shift algorithm is that there exists some\n",
    "probability density function from which the data is drawn, and tries to\n",
    "place centroids of clusters at the maxima of that density function. It\n",
    "approximates this via kernel density estimation techniques, and the key\n",
    "parameter is then the bandwidth of the kernel used. This is easier to\n",
    "guess than the number of clusters, but may require some staring at, say,\n",
    "the distributions of pairwise distances between data points to choose\n",
    "successfully. The other issue (at least with the sklearn implementation)\n",
    "is that it is fairly slow depsite potentially having good scaling!''\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}9}]:} \\PY{n}{vs1} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{cinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "\n",
    "        ---------------------------------------------------------------------------\n",
    "\n",
    "        TypeError                                 Traceback (most recent call last)\n",
    "\n",
    "        <ipython-input-9-9fb8ef8d184e> in <module>()\n",
    "    ----> 1 vs1 = plot\\_results(1,0,0,cinds=[0],dinds=[0])\n",
    "    \n",
    "\n",
    "        /mnt/c/Users/Jericho O'Connell/Documents/hdbscan/notebooks/clustering\\_comparison.py in plot\\_results(sc, sr, sv, sv2, srs, mode, w\\_positions, scale, algo\\_params, rng, cinds, return\\_vs, return\\_bars, dinds, save, title, red, out, return\\_AIC, fake, **kwargs)\n",
    "        192 \\#             bandwidth = None\n",
    "        193 \\#         else:\n",
    "    --> 194         bandwidth = cluster.estimate\\_bandwidth(X, quantile=params['quantile'])\n",
    "        195 \n",
    "        196 \\#         if mode != 'se':\n",
    "    \n",
    "\n",
    "        \\textasciitilde{}/anaconda3/lib/python3.5/site-packages/sklearn/cluster/mean\\_shift\\_.py in estimate\\_bandwidth(X, quantile, n\\_samples, random\\_state, n\\_jobs)\n",
    "         75         n\\_neighbors = 1\n",
    "         76     nbrs = NearestNeighbors(n\\_neighbors=n\\_neighbors,\n",
    "    ---> 77                             n\\_jobs=n\\_jobs)\n",
    "         78     nbrs.fit(X)\n",
    "         79 \n",
    "    \n",
    "\n",
    "        \\textasciitilde{}/anaconda3/lib/python3.5/site-packages/sklearn/neighbors/unsupervised.py in \\_\\_init\\_\\_(self, n\\_neighbors, radius, algorithm, leaf\\_size, metric, p, metric\\_params, n\\_jobs, **kwargs)\n",
    "        118                  algorithm='auto', leaf\\_size=30, metric='minkowski',\n",
    "        119                  p=2, metric\\_params=None, n\\_jobs=None, **kwargs):\n",
    "    --> 120         super(NearestNeighbors, self).\\_\\_init\\_\\_(\n",
    "        121               n\\_neighbors=n\\_neighbors,\n",
    "        122               radius=radius,\n",
    "    \n",
    "\n",
    "        TypeError: super(type, obj): obj must be an instance or subtype of type\n",
    "\n",
    "    \\end{Verbatim}\n",
    "\n",
    "    \n",
    "    \\begin{verbatim}\n",
    "<Figure size 1512x900 with 0 Axes>\n",
    "    \\end{verbatim}\n",
    "\n",
    "    \n",
    "    \\hypertarget{results}{%\n",
    "\\subsection{Results}\\label{results}}\n",
    "\n",
    "    \\hypertarget{comparison-of-different-dimensional-reduction-methods}{%\n",
    "\\subsection{Comparison of different Dimensional Reduction\n",
    "methods}\\label{comparison-of-different-dimensional-reduction-methods}}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}10}]:} \\PY{n}{bars\\PYZus{}nmf} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{all}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{red}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{nmf}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
    "         \\PY{n}{bars\\PYZus{}ica} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{all}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{red}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{ica}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
    "         \\PY{n}{bars\\PYZus{}pca} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "/home/jerichooconnell/anaconda3/lib/python3.5/site-packages/sklearn/mixture/base.py:268: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max\\_iter, tol or check for degenerate data.\n",
    "  \\% (init + 1), ConvergenceWarning)\n",
    "\n",
    "    \\end{Verbatim}\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_44_1.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_44_2.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_44_3.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}12}]:} \\PY{n}{compare\\PYZus{}3}\\PY{p}{(}\\PY{n}{bars\\PYZus{}nmf}\\PY{p}{,}\\PY{n}{bars\\PYZus{}ica}\\PY{p}{,}\\PY{n}{bars\\PYZus{}pca}\\PY{p}{,}\\PY{n}{title}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Average V\\PYZhy{}measure Dimensional Reduction Methods}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{leg}\\PY{o}{=}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{NMF}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{ICA}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{PCA}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_45_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    As can be seen above in figure \\ref{???} PCA dimensional reduction was\n",
    "seen to be superior averaged over all of the materials in all cases and\n",
    "among the algorithm examined the Gaussian Mixtures performed the best\n",
    "with the PCA dimensional reduction. If we look at cluster plots of the\n",
    "points in the clustering \\ref{???}:\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}16}]:} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{all}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{red}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{nmf}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{2}\\PY{p}{]}\\PY{p}{,}\\PY{n}{cinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{10}\\PY{p}{]}\\PY{p}{)}\n",
    "         \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{all}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{red}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{ica}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{2}\\PY{p}{]}\\PY{p}{,}\\PY{n}{cinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{10}\\PY{p}{]}\\PY{p}{)}\n",
    "         \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{2}\\PY{p}{]}\\PY{p}{,}\\PY{n}{cinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{10}\\PY{p}{]}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_47_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_47_1.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_47_2.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_47_3.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_47_4.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_47_5.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor} }]:} \\PY{n}{fname} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+s1}{.txt}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{n}{section}\\PY{p}{,}\\PY{n}{subsection}\\PY{p}{)}\n",
    "        \\PY{n}{subsection} \\PY{o}{+}\\PY{o}{=} \\PY{l+m+mi}{1}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    These figures show bluebelt seperated using the the three dimensional\n",
    "reduction methods using a bGMM model for clustering. bGMM was used since\n",
    "it has the highest score averaged over all of the reduction methods. One\n",
    "can see that NMF does not result in a clean seperation in the data and\n",
    "thus had a poor result using bGMM. Similarly the seperation using the\n",
    "ICA was more complete but did not approach the PCA in terms of\n",
    "completeness.\n",
    "\n",
    "We can also add the spacial data to the features and then try the\n",
    "dimensional reduction, but first we must normalize and put the mean to\n",
    "zero in the spatial data, adding this we get:\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}23}]:} \\PY{n}{bars\\PYZus{}nmf} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{all}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{red}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{nmf}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{4}\\PY{p}{]}\\PY{p}{)}\n",
    "         \\PY{n}{bars\\PYZus{}ica} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{all}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{red}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{ica}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{4}\\PY{p}{]}\\PY{p}{)}\n",
    "         \\PY{n}{bars\\PYZus{}pca} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{pca}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{4}\\PY{p}{]}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_50_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_50_1.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_50_2.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}24}]:} \\PY{n}{compare\\PYZus{}3}\\PY{p}{(}\\PY{n}{bars\\PYZus{}nmf}\\PY{p}{,}\\PY{n}{bars\\PYZus{}ica}\\PY{p}{,}\\PY{n}{bars\\PYZus{}pca}\\PY{p}{,}\\PY{n}{title}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Hard Materials Dimensional Reduction Methods}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{leg}\\PY{o}{=}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{NMF}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{ICA}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{PCA}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_51_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor} }]:} \\PY{n}{fname} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+s1}{.txt}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{n}{section}\\PY{p}{,}\\PY{n}{subsection}\\PY{p}{)}\n",
    "        \\PY{n}{subsection} \\PY{o}{+}\\PY{o}{=} \\PY{l+m+mi}{1}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    We can see that NMF has a lot of success in the seperation of the\n",
    "different materials if the materials are hard. In fact we see that for\n",
    "hard materials NMF is the best method in terms of V-measure with a\n",
    "V-measure of 0.92 in glass and 0.83 in steel using the bGMM clustering\n",
    "method.\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}25}]:} \\PY{n}{bars\\PYZus{}nmf} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{all}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{red}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{nmf}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{4}\\PY{p}{]}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_54_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_54_1.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\hypertarget{comparison-of-soft-and-hard-materials}{%\n",
    "\\subsubsection{Comparison of soft and hard\n",
    "Materials}\\label{comparison-of-soft-and-hard-materials}}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor} }]:} \\PY{n}{fname} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+s1}{.txt}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{n}{section}\\PY{p}{,}\\PY{n}{subsection}\\PY{p}{)}\n",
    "        \\PY{n}{subsection} \\PY{o}{+}\\PY{o}{=} \\PY{l+m+mi}{1}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    Continuing our examination of the difference between the soft and hard\n",
    "materials that we started in the above section one can see a full\n",
    "comparison below using PCA as the dimensional reduction method as it was\n",
    "shown to be the best on average.\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}26}]:} \\PY{n}{bars\\PYZus{}hard} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{4}\\PY{p}{]}\\PY{p}{,}\\PY{n}{out}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "         \\PY{n}{bars\\PYZus{}soft} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{2}\\PY{p}{,}\\PY{l+m+mi}{3}\\PY{p}{]}\\PY{p}{,}\\PY{n}{out}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_58_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_58_1.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_58_2.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}27}]:} \\PY{n}{compare\\PYZus{}2}\\PY{p}{(}\\PY{n}{bars\\PYZus{}hard}\\PY{p}{,}\\PY{n}{bars\\PYZus{}soft}\\PY{p}{,}\\PY{n}{title}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{V Measure Hard and Soft Tissues}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{leg}\\PY{o}{=}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{hard}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{soft}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_59_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor} }]:} \\PY{n}{fname} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+s1}{.txt}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{n}{section}\\PY{p}{,}\\PY{n}{subsection}\\PY{p}{)}\n",
    "        \\PY{n}{subsection} \\PY{o}{+}\\PY{o}{=} \\PY{l+m+mi}{1}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    Looking at figure \\ref{???} one immediatly sees two things: Firstly that\n",
    "the hard tissues are on average easier to cluster by all of the\n",
    "clustering algorithms as expected due to the different in density\n",
    "relative to the PMMA. Secondly, one can see that we have a clean winner\n",
    "in terms of clustering algorithms as bGMM holds the highest V-measure\n",
    "for both soft and hard tissues. Thus one can recommend the use of bGMM\n",
    "as the clustering method of choice for spectral imaging. The V-measure\n",
    "for bGMM was seen to be 0.69 for the soft tissues and 0.80 for the hard\n",
    "tissues.\n",
    "\n",
    "    \\hypertarget{dual-and-single-energy-comparison}{%\n",
    "\\subsubsection{Dual and Single Energy\n",
    "Comparison}\\label{dual-and-single-energy-comparison}}\n",
    "\n",
    "    When using spectral imaging it is important to quantify the benefits of\n",
    "the extra information over that of conventional single energy integrated\n",
    "imaging and dual energy imaging. In figure \\ref{???} one sees the\n",
    "results of the comparison between single, dual and spectral imaging.\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}40}]:} \\PY{n}{bars\\PYZus{}se} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{se}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{out}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "         \\PY{n}{bars\\PYZus{}de} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{de}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{out}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "         \\PY{n}{bars\\PYZus{}pc} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{out}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}41}]:} \\PY{n}{compare\\PYZus{}3}\\PY{p}{(}\\PY{n}{bars\\PYZus{}se}\\PY{p}{,}\\PY{n}{bars\\PYZus{}de}\\PY{p}{,}\\PY{n}{bars\\PYZus{}pc}\\PY{p}{,}\\PY{n}{title}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{V measure Different Energies}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_65_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    We can see that the spectral imaging and dual energy imaging have a\n",
    "slight advantage over single energy imaging. Again looking at the V\n",
    "Meaure for the bGMM since it is the top performing algorithm we see that\n",
    "spectral imaging has on average a score of 0.73 trailed by dual energy\n",
    "at 0.69 and single energy at 0.67. Looking at these numbers it seems\n",
    "that perhaps a 5\\% gain in V-meaure over dual energy is not worth the\n",
    "cost of spectral detectors however when looking at the performance\n",
    "seperating hard and soft tissues we see a different story.\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}69}]:} \\PY{n}{bars\\PYZus{}se} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{se}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{2}\\PY{p}{,}\\PY{l+m+mi}{3}\\PY{p}{]}\\PY{p}{,}\\PY{n}{out}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "         \\PY{n}{bars\\PYZus{}de} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{de}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{2}\\PY{p}{,}\\PY{l+m+mi}{3}\\PY{p}{]}\\PY{p}{,}\\PY{n}{out}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "         \\PY{n}{bars\\PYZus{}pc} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{2}\\PY{p}{,}\\PY{l+m+mi}{3}\\PY{p}{]}\\PY{p}{,}\\PY{n}{out}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "/home/jerichooconnell/anaconda3/lib/python3.5/site-packages/sklearn/cluster/hierarchical.py:243: UserWarning: the number of connected components of the connectivity matrix is 182 > 1. Completing it to avoid stopping the tree early.\n",
    "  affinity='euclidean')\n",
    "/home/jerichooconnell/anaconda3/lib/python3.5/site-packages/sklearn/cluster/hierarchical.py:243: UserWarning: the number of connected components of the connectivity matrix is 172 > 1. Completing it to avoid stopping the tree early.\n",
    "  affinity='euclidean')\n",
    "/home/jerichooconnell/anaconda3/lib/python3.5/site-packages/sklearn/mixture/base.py:268: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max\\_iter, tol or check for degenerate data.\n",
    "  \\% (init + 1), ConvergenceWarning)\n",
    "/home/jerichooconnell/anaconda3/lib/python3.5/site-packages/sklearn/cluster/hierarchical.py:243: UserWarning: the number of connected components of the connectivity matrix is 169 > 1. Completing it to avoid stopping the tree early.\n",
    "  affinity='euclidean')\n",
    "\n",
    "    \\end{Verbatim}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}60}]:} \\PY{n}{compare\\PYZus{}3}\\PY{p}{(}\\PY{n}{bars\\PYZus{}se}\\PY{p}{,}\\PY{n}{bars\\PYZus{}de}\\PY{p}{,}\\PY{n}{bars\\PYZus{}pc}\\PY{p}{,}\\PY{n}{title}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{V measure Different Energies}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_68_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    Figure \\ref{???} shows that although on average the gain is quite\n",
    "marginal between spectral and other energy combination when it comes to\n",
    "soft materials over all of the different clustering methods. This gain\n",
    "is quite substantial, for instance the bGMM for dual energy has a 21\\%\n",
    "gain over dual energy jumping from 0.57 to 0.69.\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}72}]:} \\PY{n}{bars\\PYZus{}se} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{se}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{4}\\PY{p}{]}\\PY{p}{,}\\PY{n}{out}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "         \\PY{n}{bars\\PYZus{}de} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{mode}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{de}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{4}\\PY{p}{]}\\PY{p}{,}\\PY{n}{out}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "         \\PY{n}{bars\\PYZus{}pc} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{return\\PYZus{}vs}\\PY{o}{=}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{return\\PYZus{}bars}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{dinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{4}\\PY{p}{]}\\PY{p}{,}\\PY{n}{out}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_70_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}65}]:} \\PY{n}{compare\\PYZus{}3}\\PY{p}{(}\\PY{n}{bars\\PYZus{}se}\\PY{p}{,}\\PY{n}{bars\\PYZus{}de}\\PY{p}{,}\\PY{n}{bars\\PYZus{}pc}\\PY{p}{,}\\PY{n}{title}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{V measure Different Energies}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_71_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    We see that in the hard material case we have much worse performance of\n",
    "the spectral detector relative to the single and dual energy case. This\n",
    "is understandable since in the case of hard materials the pixels can be\n",
    "linearly seperated based on their density alone and the attenuation of\n",
    "the materials as a function of energy is redundant information as the\n",
    "two materials are already seperable in one dimension. In fact, the\n",
    "seperation of the energy bins incurres a cost of worse photon\n",
    "statistics. If we approximate the fit as the result of \\(n\\) poisson\n",
    "variables then the noise for a fit using \\(n\\) bins of equal fluence\n",
    "will for the worst case have \\(\\sqrt{n}\\) more noise if the bins are\n",
    "treated independantly. In this work the bGMM has a 11\\% reduction in V\n",
    "measure as compared to the single energy case with a value of 0.89 as\n",
    "compared to 0.802. Interestingly, comparing this value to the NMF result\n",
    "in figure \\ref{???} we note that in fact the NMF with the spectral\n",
    "imaging produces a higher V measure on the steel than the single energy\n",
    "image and a slightly lower value on the glass, although still higher\n",
    "than the values for the glass using PCA spectral imaging.\n",
    "\n",
    "    \\hypertarget{measure-of-number-of-bins}{%\n",
    "\\subsubsection{Measure of Number of\n",
    "Bins}\\label{measure-of-number-of-bins}}\n",
    "\n",
    "    An important note in this work is that many of the algorithms take as a\n",
    "parameter the number of bins to be used in the fit. There are multiple\n",
    "metrics for determining the number of bins for various algorithms. Since\n",
    "bGMM was seen to perform the best on the dataset we will focus on\n",
    "methods for determining the number for this algorithm.\n",
    "\n",
    "    AIC was used as the determining factor for the number of bins. A maximum\n",
    "number of bins was set to two for this study as the main differentiation\n",
    "we are looking for is between one and two materials. However it is\n",
    "possible to allow more bins for looking at a larger variety of\n",
    "materials.\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}104}]:} \\PY{n}{aic\\PYZus{}2} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{cinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{9}\\PY{p}{]}\\PY{p}{,}\\PY{n}{return\\PYZus{}AIC}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{,}\\PY{n}{out}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "          \\PY{n}{aic\\PYZus{}1} \\PY{o}{=} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{cinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{9}\\PY{p}{]}\\PY{p}{,}\\PY{n}{algo\\PYZus{}params}\\PY{o}{=}\\PY{p}{\\PYZob{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{n\\PYZus{}clusters}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{l+m+mi}{1}\\PY{p}{\\PYZcb{}}\\PY{p}{,}\\PY{n}{return\\PYZus{}AIC}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{,}\\PY{n}{out}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}116}]:} \\PY{n}{compare\\PYZus{}2}\\PY{p}{(}\\PY{n}{aic\\PYZus{}2}\\PY{p}{,}\\PY{n}{aic\\PYZus{}1}\\PY{p}{,}\\PY{n}{title}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{AIC for 1 and 2 clusters}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{leg}\\PY{o}{=}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{2 Clusters}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{1 Cluster}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,}\\PY{n}{algo}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_77_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    As one can see above for all of the materials it is seen that it is\n",
    "preferable to the two energy approach.\n",
    "\n",
    "    \\hypertarget{real-data}{%\n",
    "\\subsubsection{Real Data}\\label{real-data}}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}129}]:} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{n}{fake}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_80_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_80_1.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    The above image is the seperation\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}67}]:} \\PY{k+kn}{from} \\PY{n+nn}{IPython}\\PY{n+nn}{.}\\PY{n+nn}{display} \\PY{k}{import} \\PY{n}{HTML}\\PY{p}{,} \\PY{n}{display}\n",
    "         \n",
    "         \\PY{n}{data} \\PY{o}{=} \\PY{p}{[}\\PY{n}{np}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{n}{bars\\PYZus{}se}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{)}\\PY{p}{,}\\PY{n}{np}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{n}{bars\\PYZus{}de}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{)}\\PY{p}{,}\\PY{n}{np}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{n}{bars\\PYZus{}pc}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{)}\n",
    "                 \\PY{p}{]}\n",
    "         \n",
    "         \\PY{n}{display}\\PY{p}{(}\\PY{n}{HTML}\\PY{p}{(}\n",
    "            \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{\\PYZlt{}table\\PYZgt{}\\PYZlt{}tr\\PYZgt{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+s1}{\\PYZlt{}/tr\\PYZgt{}\\PYZlt{}/table\\PYZgt{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\n",
    "                \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{\\PYZlt{}/tr\\PYZgt{}\\PYZlt{}tr\\PYZgt{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{join}\\PY{p}{(}\n",
    "                    \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{\\PYZlt{}td\\PYZgt{}}\\PY{l+s+si}{\\PYZob{}\\PYZcb{}}\\PY{l+s+s1}{\\PYZlt{}/td\\PYZgt{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{\\PYZlt{}/td\\PYZgt{}\\PYZlt{}td\\PYZgt{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{o}{.}\\PY{n}{join}\\PY{p}{(}\\PY{n+nb}{str}\\PY{p}{(}\\PY{n}{\\PYZus{}}\\PY{p}{)} \\PY{k}{for} \\PY{n}{\\PYZus{}} \\PY{o+ow}{in} \\PY{n}{row}\\PY{p}{)}\\PY{p}{)} \\PY{k}{for} \\PY{n}{row} \\PY{o+ow}{in} \\PY{n}{data}\\PY{p}{)}\n",
    "                \\PY{p}{)}\n",
    "         \\PY{p}{)}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \n",
    "    \\begin{verbatim}\n",
    "<IPython.core.display.HTML object>\n",
    "    \\end{verbatim}\n",
    "\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}50}]:} \\PY{n}{np}\\PY{o}{.}\\PY{n}{mean}\\PY{p}{(}\\PY{n}{bars\\PYZus{}se}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{outcolor}Out[{\\color{outcolor}50}]:} array([0.52454242, 0.34701285, 0.21311304, 0.50097276, 0.49058416,\n",
    "                0.32251711, 0.66968022, 0.67002609])\n",
    "\\end{Verbatim}\n",
    "            \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}62}]:} \\PY{p}{(}\\PY{l+m+mf}{0.69}\\PY{o}{\\PYZhy{}}\\PY{l+m+mf}{0.568}\\PY{p}{)}\\PY{o}{/}\\PY{l+m+mf}{0.568}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{outcolor}Out[{\\color{outcolor}62}]:} 0.21478873239436622\n",
    "\\end{Verbatim}\n",
    "            \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}74}]:} \\PY{n}{bars\\PYZus{}pc}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{outcolor}Out[{\\color{outcolor}74}]:} [array([0.67690581, 0.66419897, 0.62436189, 0.67690581, 0.67690581,\n",
    "                 0.71399662, 0.76517477, 0.79270167]),\n",
    "          array([0.57321049, 0.67293471, 0.6151895 , 0.6151895 , 0.6151895 ,\n",
    "                 0.56085799, 0.71994535, 0.81162428])]\n",
    "\\end{Verbatim}\n",
    "            \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}126}]:} \\PY{l+m+mi}{68}\\PY{o}{*}\\PY{l+m+mi}{10}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{outcolor}Out[{\\color{outcolor}126}]:} 680\n",
    "\\end{Verbatim}\n",
    "            \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}16}]:} \\PY{n}{compare\\PYZus{}2}\\PY{p}{(}\\PY{n}{aic\\PYZus{}2}\\PY{p}{,}\\PY{n}{aic\\PYZus{}1}\\PY{p}{,}\\PY{n}{title}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{AIC for 1 and 2 clusters}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{n}{leg}\\PY{o}{=}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{2 Clusters}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{1 Cluster}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,}\\PY{n}{algo}\\PY{o}{=}\\PY{k+kc}{False}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_87_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}19}]:} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{cinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{10}\\PY{p}{]}\\PY{p}{,}\\PY{n}{algo\\PYZus{}params}\\PY{o}{=}\\PY{p}{\\PYZob{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{ct}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{spherical}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_88_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_88_1.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}20}]:} \\PY{n}{plot\\PYZus{}results}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{n}{cinds}\\PY{o}{=}\\PY{p}{[}\\PY{l+m+mi}{10}\\PY{p}{]}\\PY{p}{,}\\PY{n}{algo\\PYZus{}params}\\PY{o}{=}\\PY{p}{\\PYZob{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{ct}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{full}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_89_0.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_89_1.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\hypertarget{filtering-of-the-data}{%\n",
    "\\subsubsection{Filtering of the Data}\\label{filtering-of-the-data}}\n",
    "\n",
    "    To better fit the data a new method was introduced to reduce noise and\n",
    "eliminate outliers that would show up positive on the scan. When\n",
    "scanning one would not be concerned with contaminants on the order of\n",
    "1-5 pixels as these could likely be the product of noise and lead to\n",
    "false positives. The question being what size of contaminant do we wish\n",
    "to recognize since the probability of a random cluster of noisy points\n",
    "in the data is high we think this should be a relatively large amount.\n",
    "For small groups of points in the image this method will likely\n",
    "interpolate them into the background. But for larger groups of points in\n",
    "the image, this method will further seperate the clusters. Thus we\n",
    "present a method that is much more robust in that it will eliminate\n",
    "redundant clusters if a cluster is not dense and it's points are at the\n",
    "edge of it's gaussian distribution. However, if the two gaussian mixed\n",
    "models contain real gaussian distribution this methods reduces variance\n",
    "in the mixtures and successfully reasigns many points at the edge of the\n",
    "cluster.\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor} }]:} \\PY{n}{plt}\\PY{o}{.}\\PY{n}{quiver}\\PY{p}{(}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}23}]:} \\PY{k+kn}{import} \\PY{n+nn}{pcpursuit}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}46}]:} \\PY{n}{M} \\PY{o}{=} \\PY{n}{loadmat}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{allbb.mat}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Z}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{:}\\PY{p}{]}\n",
    "         \n",
    "         \\PY{n}{L}\\PY{p}{,} \\PY{n}{S}\\PY{p}{,} \\PY{p}{(}\\PY{n}{u}\\PY{p}{,} \\PY{n}{s}\\PY{p}{,} \\PY{n}{v}\\PY{p}{)} \\PY{o}{=} \\PY{n}{pcpursuit}\\PY{o}{.}\\PY{n}{pcp}\\PY{p}{(}\\PY{n}{M}\\PY{p}{,} \\PY{n}{maxiter}\\PY{o}{=}\\PY{l+m+mi}{200}\\PY{p}{,} \\PY{n}{verbose}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{,} \\PY{n}{svd\\PYZus{}method}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{exact}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "mu = 1.2286592162622392\n",
    "Iteration 0: error=4.993e-02, rank=1, nnz=16, time=0.000e+00\n",
    "Iteration 1: error=1.145e-02, rank=1, nnz=144, time=1.072e-03\n",
    "Iteration 2: error=9.928e-03, rank=1, nnz=377, time=1.010e-03\n",
    "Iteration 3: error=8.540e-03, rank=1, nnz=659, time=1.009e-03\n",
    "Iteration 4: error=7.353e-03, rank=1, nnz=957, time=1.027e-03\n",
    "Iteration 5: error=6.462e-03, rank=1, nnz=1219, time=1.030e-03\n",
    "Iteration 6: error=5.655e-03, rank=1, nnz=1472, time=0.000e+00\n",
    "Iteration 7: error=5.052e-03, rank=1, nnz=1660, time=0.000e+00\n",
    "Iteration 8: error=4.526e-03, rank=1, nnz=1862, time=1.045e-03\n",
    "Iteration 9: error=4.028e-03, rank=1, nnz=2061, time=1.057e-03\n",
    "Iteration 10: error=3.615e-03, rank=1, nnz=2224, time=1.008e-03\n",
    "Iteration 11: error=3.306e-03, rank=1, nnz=2354, time=0.000e+00\n",
    "Iteration 12: error=3.033e-03, rank=1, nnz=2468, time=0.000e+00\n",
    "Iteration 13: error=2.761e-03, rank=1, nnz=2566, time=0.000e+00\n",
    "Iteration 14: error=2.532e-03, rank=1, nnz=2667, time=4.000e-03\n",
    "Iteration 15: error=2.324e-03, rank=1, nnz=2767, time=0.000e+00\n",
    "Iteration 16: error=2.127e-03, rank=1, nnz=2856, time=0.000e+00\n",
    "Iteration 17: error=1.964e-03, rank=1, nnz=2909, time=0.000e+00\n",
    "Iteration 18: error=1.841e-03, rank=1, nnz=2961, time=3.995e-03\n",
    "Iteration 19: error=1.724e-03, rank=1, nnz=3015, time=0.000e+00\n",
    "Iteration 20: error=1.613e-03, rank=1, nnz=3051, time=0.000e+00\n",
    "Iteration 21: error=1.504e-03, rank=1, nnz=3103, time=0.000e+00\n",
    "Iteration 22: error=1.391e-03, rank=1, nnz=3150, time=0.000e+00\n",
    "Iteration 23: error=1.300e-03, rank=1, nnz=3193, time=3.994e-03\n",
    "Iteration 24: error=1.216e-03, rank=1, nnz=3236, time=0.000e+00\n",
    "Iteration 25: error=1.138e-03, rank=1, nnz=3274, time=3.995e-03\n",
    "Iteration 26: error=1.073e-03, rank=1, nnz=3307, time=0.000e+00\n",
    "Iteration 27: error=1.014e-03, rank=1, nnz=3324, time=0.000e+00\n",
    "Iteration 28: error=9.702e-04, rank=1, nnz=3349, time=0.000e+00\n",
    "Iteration 29: error=9.191e-04, rank=1, nnz=3367, time=0.000e+00\n",
    "Iteration 30: error=8.669e-04, rank=1, nnz=3393, time=0.000e+00\n",
    "Iteration 31: error=8.238e-04, rank=1, nnz=3415, time=0.000e+00\n",
    "Iteration 32: error=7.846e-04, rank=1, nnz=3432, time=0.000e+00\n",
    "Iteration 33: error=7.504e-04, rank=1, nnz=3459, time=0.000e+00\n",
    "Iteration 34: error=7.162e-04, rank=1, nnz=3479, time=0.000e+00\n",
    "Iteration 35: error=6.857e-04, rank=1, nnz=3497, time=0.000e+00\n",
    "Iteration 36: error=6.527e-04, rank=1, nnz=3518, time=0.000e+00\n",
    "Iteration 37: error=6.239e-04, rank=1, nnz=3534, time=0.000e+00\n",
    "Iteration 38: error=5.981e-04, rank=1, nnz=3546, time=0.000e+00\n",
    "Iteration 39: error=5.747e-04, rank=1, nnz=3562, time=0.000e+00\n",
    "Iteration 40: error=5.487e-04, rank=1, nnz=3580, time=0.000e+00\n",
    "Iteration 41: error=5.272e-04, rank=1, nnz=3593, time=3.996e-03\n",
    "Iteration 42: error=5.074e-04, rank=1, nnz=3606, time=0.000e+00\n",
    "Iteration 43: error=4.896e-04, rank=1, nnz=3621, time=0.000e+00\n",
    "Iteration 44: error=4.729e-04, rank=1, nnz=3629, time=3.993e-03\n",
    "Iteration 45: error=4.563e-04, rank=1, nnz=3640, time=0.000e+00\n",
    "Iteration 46: error=4.401e-04, rank=1, nnz=3649, time=0.000e+00\n",
    "Iteration 47: error=4.281e-04, rank=1, nnz=3657, time=0.000e+00\n",
    "Iteration 48: error=4.127e-04, rank=1, nnz=3671, time=0.000e+00\n",
    "Iteration 49: error=3.969e-04, rank=1, nnz=3677, time=0.000e+00\n",
    "Iteration 50: error=3.844e-04, rank=1, nnz=3684, time=0.000e+00\n",
    "Iteration 51: error=3.738e-04, rank=1, nnz=3694, time=0.000e+00\n",
    "Iteration 52: error=3.626e-04, rank=1, nnz=3703, time=0.000e+00\n",
    "Iteration 53: error=3.504e-04, rank=1, nnz=3713, time=0.000e+00\n",
    "Iteration 54: error=3.392e-04, rank=1, nnz=3725, time=0.000e+00\n",
    "Iteration 55: error=3.266e-04, rank=2, nnz=3729, time=0.000e+00\n",
    "Iteration 56: error=3.152e-04, rank=2, nnz=3733, time=0.000e+00\n",
    "Iteration 57: error=3.067e-04, rank=2, nnz=3737, time=0.000e+00\n",
    "Iteration 58: error=2.982e-04, rank=2, nnz=3740, time=0.000e+00\n",
    "Iteration 59: error=2.910e-04, rank=2, nnz=3745, time=0.000e+00\n",
    "Iteration 60: error=2.811e-04, rank=2, nnz=3750, time=0.000e+00\n",
    "Iteration 61: error=2.695e-04, rank=2, nnz=3759, time=3.993e-03\n",
    "Iteration 62: error=2.598e-04, rank=2, nnz=3761, time=0.000e+00\n",
    "Iteration 63: error=2.515e-04, rank=2, nnz=3762, time=0.000e+00\n",
    "Iteration 64: error=2.461e-04, rank=2, nnz=3767, time=0.000e+00\n",
    "Iteration 65: error=2.408e-04, rank=2, nnz=3773, time=3.996e-03\n",
    "Iteration 66: error=2.363e-04, rank=2, nnz=3773, time=0.000e+00\n",
    "Iteration 67: error=2.332e-04, rank=2, nnz=3774, time=0.000e+00\n",
    "Iteration 68: error=2.277e-04, rank=2, nnz=3772, time=0.000e+00\n",
    "Iteration 69: error=2.205e-04, rank=2, nnz=3772, time=0.000e+00\n",
    "Iteration 70: error=2.132e-04, rank=2, nnz=3773, time=0.000e+00\n",
    "Iteration 71: error=2.090e-04, rank=2, nnz=3775, time=0.000e+00\n",
    "Iteration 72: error=2.072e-04, rank=2, nnz=3777, time=0.000e+00\n",
    "Iteration 73: error=2.058e-04, rank=2, nnz=3776, time=0.000e+00\n",
    "Iteration 74: error=2.036e-04, rank=2, nnz=3780, time=0.000e+00\n",
    "Iteration 75: error=1.994e-04, rank=2, nnz=3783, time=3.996e-03\n",
    "Iteration 76: error=1.956e-04, rank=2, nnz=3786, time=0.000e+00\n",
    "Iteration 77: error=1.910e-04, rank=2, nnz=3788, time=0.000e+00\n",
    "Iteration 78: error=1.876e-04, rank=2, nnz=3791, time=0.000e+00\n",
    "Iteration 79: error=1.843e-04, rank=2, nnz=3792, time=0.000e+00\n",
    "Iteration 80: error=1.791e-04, rank=2, nnz=3796, time=0.000e+00\n",
    "Iteration 81: error=1.732e-04, rank=2, nnz=3797, time=0.000e+00\n",
    "Iteration 82: error=1.692e-04, rank=2, nnz=3798, time=3.995e-03\n",
    "Iteration 83: error=1.672e-04, rank=2, nnz=3800, time=0.000e+00\n",
    "Iteration 84: error=1.631e-04, rank=2, nnz=3803, time=0.000e+00\n",
    "Iteration 85: error=1.590e-04, rank=2, nnz=3805, time=0.000e+00\n",
    "Iteration 86: error=1.554e-04, rank=2, nnz=3808, time=0.000e+00\n",
    "Iteration 87: error=1.512e-04, rank=2, nnz=3811, time=0.000e+00\n",
    "Iteration 88: error=1.464e-04, rank=2, nnz=3816, time=0.000e+00\n",
    "Iteration 89: error=1.419e-04, rank=2, nnz=3819, time=0.000e+00\n",
    "Iteration 90: error=1.388e-04, rank=2, nnz=3821, time=0.000e+00\n",
    "Iteration 91: error=1.369e-04, rank=2, nnz=3823, time=0.000e+00\n",
    "Iteration 92: error=1.342e-04, rank=2, nnz=3831, time=3.995e-03\n",
    "Iteration 93: error=1.321e-04, rank=2, nnz=3833, time=0.000e+00\n",
    "Iteration 94: error=1.302e-04, rank=2, nnz=3836, time=0.000e+00\n",
    "Iteration 95: error=1.287e-04, rank=2, nnz=3839, time=3.995e-03\n",
    "Iteration 96: error=1.273e-04, rank=2, nnz=3841, time=0.000e+00\n",
    "Iteration 97: error=1.254e-04, rank=2, nnz=3844, time=0.000e+00\n",
    "Iteration 98: error=1.236e-04, rank=2, nnz=3844, time=0.000e+00\n",
    "Iteration 99: error=1.223e-04, rank=2, nnz=3847, time=0.000e+00\n",
    "Iteration 100: error=1.201e-04, rank=2, nnz=3848, time=0.000e+00\n",
    "Iteration 101: error=1.180e-04, rank=2, nnz=3851, time=0.000e+00\n",
    "Iteration 102: error=1.163e-04, rank=2, nnz=3854, time=3.994e-03\n",
    "Iteration 103: error=1.150e-04, rank=2, nnz=3854, time=0.000e+00\n",
    "Iteration 104: error=1.135e-04, rank=2, nnz=3856, time=0.000e+00\n",
    "Iteration 105: error=1.119e-04, rank=2, nnz=3858, time=0.000e+00\n",
    "Iteration 106: error=1.096e-04, rank=2, nnz=3866, time=3.995e-03\n",
    "Iteration 107: error=1.063e-04, rank=2, nnz=3868, time=0.000e+00\n",
    "Iteration 108: error=1.041e-04, rank=2, nnz=3870, time=0.000e+00\n",
    "Iteration 109: error=1.028e-04, rank=2, nnz=3872, time=0.000e+00\n",
    "Iteration 110: error=1.007e-04, rank=2, nnz=3874, time=0.000e+00\n",
    "Iteration 111: error=9.837e-05, rank=2, nnz=3875, time=0.000e+00\n",
    "Iteration 112: error=9.553e-05, rank=2, nnz=3879, time=0.000e+00\n",
    "Iteration 113: error=9.332e-05, rank=2, nnz=3881, time=0.000e+00\n",
    "Iteration 114: error=9.200e-05, rank=2, nnz=3884, time=0.000e+00\n",
    "Iteration 115: error=9.048e-05, rank=2, nnz=3884, time=0.000e+00\n",
    "Iteration 116: error=8.923e-05, rank=2, nnz=3885, time=0.000e+00\n",
    "Iteration 117: error=8.807e-05, rank=2, nnz=3885, time=0.000e+00\n",
    "Iteration 118: error=8.692e-05, rank=2, nnz=3886, time=0.000e+00\n",
    "Iteration 119: error=8.606e-05, rank=2, nnz=3886, time=0.000e+00\n",
    "Iteration 120: error=8.488e-05, rank=2, nnz=3887, time=0.000e+00\n",
    "Iteration 121: error=8.373e-05, rank=2, nnz=3888, time=0.000e+00\n",
    "Iteration 122: error=8.306e-05, rank=2, nnz=3888, time=3.995e-03\n",
    "Iteration 123: error=8.216e-05, rank=2, nnz=3890, time=0.000e+00\n",
    "Iteration 124: error=8.138e-05, rank=2, nnz=3890, time=0.000e+00\n",
    "Iteration 125: error=8.070e-05, rank=2, nnz=3892, time=3.995e-03\n",
    "Iteration 126: error=7.999e-05, rank=2, nnz=3896, time=0.000e+00\n",
    "Iteration 127: error=7.907e-05, rank=2, nnz=3899, time=0.000e+00\n",
    "Iteration 128: error=7.754e-05, rank=2, nnz=3901, time=0.000e+00\n",
    "Iteration 129: error=7.572e-05, rank=2, nnz=3904, time=3.995e-03\n",
    "Iteration 130: error=7.401e-05, rank=2, nnz=3905, time=0.000e+00\n",
    "Iteration 131: error=7.307e-05, rank=2, nnz=3905, time=0.000e+00\n",
    "Iteration 132: error=7.266e-05, rank=2, nnz=3905, time=0.000e+00\n",
    "Iteration 133: error=7.247e-05, rank=2, nnz=3905, time=3.994e-03\n",
    "Iteration 134: error=7.164e-05, rank=2, nnz=3906, time=0.000e+00\n",
    "Iteration 135: error=7.074e-05, rank=2, nnz=3906, time=0.000e+00\n",
    "Iteration 136: error=7.005e-05, rank=2, nnz=3906, time=0.000e+00\n",
    "Iteration 137: error=6.927e-05, rank=2, nnz=3907, time=0.000e+00\n",
    "Iteration 138: error=6.869e-05, rank=2, nnz=3908, time=0.000e+00\n",
    "Iteration 139: error=6.799e-05, rank=2, nnz=3911, time=0.000e+00\n",
    "Iteration 140: error=6.750e-05, rank=2, nnz=3912, time=3.991e-03\n",
    "Iteration 141: error=6.673e-05, rank=2, nnz=3913, time=0.000e+00\n",
    "Iteration 142: error=6.560e-05, rank=2, nnz=3914, time=0.000e+00\n",
    "Iteration 143: error=6.420e-05, rank=2, nnz=3916, time=0.000e+00\n",
    "\n",
    "    \\end{Verbatim}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "WARNING:root:convergence not reached in pcp\n",
    "\n",
    "    \\end{Verbatim}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "Iteration 144: error=6.308e-05, rank=2, nnz=3917, time=3.994e-03\n",
    "Iteration 145: error=6.237e-05, rank=2, nnz=3917, time=0.000e+00\n",
    "Iteration 146: error=6.155e-05, rank=2, nnz=3918, time=0.000e+00\n",
    "Iteration 147: error=6.115e-05, rank=2, nnz=3918, time=0.000e+00\n",
    "Iteration 148: error=6.060e-05, rank=2, nnz=3921, time=3.993e-03\n",
    "Iteration 149: error=6.006e-05, rank=2, nnz=3921, time=0.000e+00\n",
    "Iteration 150: error=5.943e-05, rank=2, nnz=3921, time=0.000e+00\n",
    "Iteration 151: error=5.897e-05, rank=2, nnz=3922, time=0.000e+00\n",
    "Iteration 152: error=5.866e-05, rank=2, nnz=3922, time=0.000e+00\n",
    "Iteration 153: error=5.841e-05, rank=2, nnz=3922, time=7.991e-03\n",
    "Iteration 154: error=5.825e-05, rank=2, nnz=3922, time=0.000e+00\n",
    "Iteration 155: error=5.806e-05, rank=2, nnz=3925, time=0.000e+00\n",
    "Iteration 156: error=5.772e-05, rank=2, nnz=3925, time=3.993e-03\n",
    "Iteration 157: error=5.746e-05, rank=2, nnz=3926, time=0.000e+00\n",
    "Iteration 158: error=5.722e-05, rank=2, nnz=3927, time=0.000e+00\n",
    "Iteration 159: error=5.691e-05, rank=2, nnz=3928, time=3.995e-03\n",
    "Iteration 160: error=5.626e-05, rank=2, nnz=3930, time=0.000e+00\n",
    "Iteration 161: error=5.577e-05, rank=2, nnz=3931, time=0.000e+00\n",
    "Iteration 162: error=5.555e-05, rank=2, nnz=3931, time=3.999e-03\n",
    "Iteration 163: error=5.548e-05, rank=2, nnz=3931, time=0.000e+00\n",
    "Iteration 164: error=5.543e-05, rank=2, nnz=3932, time=0.000e+00\n",
    "Iteration 165: error=5.527e-05, rank=2, nnz=3932, time=3.989e-03\n",
    "Iteration 166: error=5.489e-05, rank=2, nnz=3932, time=0.000e+00\n",
    "Iteration 167: error=5.425e-05, rank=2, nnz=3933, time=0.000e+00\n",
    "Iteration 168: error=5.343e-05, rank=2, nnz=3933, time=0.000e+00\n",
    "Iteration 169: error=5.249e-05, rank=2, nnz=3936, time=3.995e-03\n",
    "Iteration 170: error=5.146e-05, rank=2, nnz=3936, time=0.000e+00\n",
    "Iteration 171: error=5.064e-05, rank=2, nnz=3940, time=0.000e+00\n",
    "Iteration 172: error=5.026e-05, rank=2, nnz=3942, time=3.997e-03\n",
    "Iteration 173: error=5.001e-05, rank=2, nnz=3942, time=0.000e+00\n",
    "Iteration 174: error=4.979e-05, rank=2, nnz=3943, time=0.000e+00\n",
    "Iteration 175: error=4.938e-05, rank=2, nnz=3944, time=3.994e-03\n",
    "Iteration 176: error=4.885e-05, rank=2, nnz=3946, time=0.000e+00\n",
    "Iteration 177: error=4.835e-05, rank=2, nnz=3947, time=0.000e+00\n",
    "Iteration 178: error=4.769e-05, rank=2, nnz=3948, time=0.000e+00\n",
    "Iteration 179: error=4.727e-05, rank=2, nnz=3949, time=0.000e+00\n",
    "Iteration 180: error=4.682e-05, rank=2, nnz=3950, time=0.000e+00\n",
    "Iteration 181: error=4.657e-05, rank=2, nnz=3950, time=0.000e+00\n",
    "Iteration 182: error=4.637e-05, rank=2, nnz=3951, time=0.000e+00\n",
    "Iteration 183: error=4.556e-05, rank=2, nnz=3953, time=0.000e+00\n",
    "Iteration 184: error=4.468e-05, rank=2, nnz=3953, time=0.000e+00\n",
    "Iteration 185: error=4.358e-05, rank=2, nnz=3954, time=0.000e+00\n",
    "Iteration 186: error=4.233e-05, rank=2, nnz=3956, time=0.000e+00\n",
    "Iteration 187: error=4.171e-05, rank=2, nnz=3957, time=0.000e+00\n",
    "Iteration 188: error=4.136e-05, rank=2, nnz=3957, time=0.000e+00\n",
    "Iteration 189: error=4.108e-05, rank=2, nnz=3957, time=0.000e+00\n",
    "Iteration 190: error=4.090e-05, rank=2, nnz=3957, time=0.000e+00\n",
    "Iteration 191: error=4.061e-05, rank=2, nnz=3957, time=3.994e-03\n",
    "Iteration 192: error=4.034e-05, rank=2, nnz=3958, time=0.000e+00\n",
    "Iteration 193: error=3.991e-05, rank=2, nnz=3958, time=0.000e+00\n",
    "Iteration 194: error=3.944e-05, rank=2, nnz=3958, time=0.000e+00\n",
    "Iteration 195: error=3.909e-05, rank=2, nnz=3958, time=3.996e-03\n",
    "Iteration 196: error=3.877e-05, rank=2, nnz=3958, time=0.000e+00\n",
    "Iteration 197: error=3.851e-05, rank=2, nnz=3959, time=0.000e+00\n",
    "Iteration 198: error=3.821e-05, rank=2, nnz=3959, time=0.000e+00\n",
    "Iteration 199: error=3.793e-05, rank=2, nnz=3961, time=3.992e-03\n",
    "\n",
    "    \\end{Verbatim}\n",
    "\n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}47}]:} \\PY{n}{plt}\\PY{o}{.}\\PY{n}{figure}\\PY{p}{(}\\PY{p}{)}\n",
    "         \\PY{n}{plt}\\PY{o}{.}\\PY{n}{scatter}\\PY{p}{(}\\PY{n}{S}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{,}\\PY{n}{S}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{]}\\PY{p}{)}\n",
    "         \\PY{c+c1}{\\PYZsh{} plt.plot(S)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{outcolor}Out[{\\color{outcolor}47}]:} <matplotlib.collections.PathCollection at 0x208d8951d68>\n",
    "\\end{Verbatim}\n",
    "            \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_95_1.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}51}]:} \\PY{n}{plt}\\PY{o}{.}\\PY{n}{figure}\\PY{p}{(}\\PY{p}{)}\n",
    "         \\PY{n}{plt}\\PY{o}{.}\\PY{n}{scatter}\\PY{p}{(}\\PY{n}{L}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{,}\\PY{n}{L}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{]}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{outcolor}Out[{\\color{outcolor}51}]:} <matplotlib.collections.PathCollection at 0x208d83ee4a8>\n",
    "\\end{Verbatim}\n",
    "            \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_96_1.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}52}]:} \\PY{n}{plt}\\PY{o}{.}\\PY{n}{imshow}\\PY{p}{(}\\PY{n}{np}\\PY{o}{.}\\PY{n}{reshape}\\PY{p}{(}\\PY{n}{L}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{]}\\PY{p}{,} \\PY{p}{(}\\PY{l+m+mi}{20}\\PY{p}{,}\\PY{l+m+mi}{68}\\PY{p}{)}\\PY{p}{,} \\PY{n}{order}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{F}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{outcolor}Out[{\\color{outcolor}52}]:} <matplotlib.image.AxesImage at 0x208d84340f0>\n",
    "\\end{Verbatim}\n",
    "            \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_97_1.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}53}]:} \\PY{n}{plt}\\PY{o}{.}\\PY{n}{imshow}\\PY{p}{(}\\PY{n}{np}\\PY{o}{.}\\PY{n}{reshape}\\PY{p}{(}\\PY{n}{S}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{l+m+mi}{1}\\PY{p}{]}\\PY{p}{,} \\PY{p}{(}\\PY{l+m+mi}{20}\\PY{p}{,}\\PY{l+m+mi}{68}\\PY{p}{)}\\PY{p}{,} \\PY{n}{order}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{F}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{outcolor}Out[{\\color{outcolor}53}]:} <matplotlib.image.AxesImage at 0x208d846f898>\n",
    "\\end{Verbatim}\n",
    "            \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_98_1.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}57}]:} \\PY{n}{plt}\\PY{o}{.}\\PY{n}{imshow}\\PY{p}{(}\\PY{n}{np}\\PY{o}{.}\\PY{n}{reshape}\\PY{p}{(}\\PY{n}{M}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{l+m+mi}{4}\\PY{p}{]}\\PY{p}{,} \\PY{p}{(}\\PY{l+m+mi}{20}\\PY{p}{,}\\PY{l+m+mi}{68}\\PY{p}{)}\\PY{p}{,} \\PY{n}{order}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{F}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
    "\\end{Verbatim}\n",
    "\n",
    "\n",
    "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{outcolor}Out[{\\color{outcolor}57}]:} <matplotlib.image.AxesImage at 0x208d85c35f8>\n",
    "\\end{Verbatim}\n",
    "            \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_99_1.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "\n",
    "    % Add a bibliography block to the postdoc\n",
    "    \n",
    "    \n",
    "    \n",
    "    \\end{document}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test2.tex\n"
     ]
    }
   ],
   "source": [
    "%%writefile test2.tex\n",
    "\n",
    "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{outcolor}Out[{\\color{outcolor}53}]:} <matplotlib.image.AxesImage at 0x208d846f898>\n",
    "\\end{Verbatim}\n",
    "            \n",
    "    \\begin{center}\n",
    "    \\adjustimage{max size={0.9\\linewidth}{0.9\\paperheight}}{draft_for_paper_files/draft_for_paper_98_1.png}\n",
    "    \\end{center}\n",
    "    { \\hspace*{\\fill} \\\\}\n",
    "    \n",
    "    \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
    "{\\color{incolor}In [{\\color{incolor}57}]:} \\PY{n}{plt}\\PY{o}{.}\\PY{n}{imshow}\\PY{p}{(}\\PY{n}{np}\\PY{o}{.}\\PY{n}{reshape}\\PY{p}{(}\\PY{n}{M}\\PY{p}{[}\\PY{p}{:}\\PY{p}{,}\\PY{l+m+mi}{4}\\PY{p}{]}\\PY{p}{,} \\PY{p}{(}\\PY{l+m+mi}{20}\\PY{p}{,}\\PY{l+m+mi}{68}\\PY{p}{)}\\PY{p}{,} \\PY{n}{order}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{F}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
    "\\end{Verbatim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"test.tex\",\"r\")\n",
    "\n",
    "lines = f.readlines()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And reopen it in write mode:\n",
    "\n",
    "f = open(\"test.tex\",\"w\")\n",
    "# Then, write your lines back, except the line you want to delete. You might want to change the \"\\n\" to whatever line ending your file uses.\n",
    "tog = 0\n",
    "\n",
    "for line in lines:\n",
    "    \n",
    "    if tog:\n",
    "        if line.strip()[0:14] == \"\\\\end{Verbatim}\":\n",
    "            tog = 0\n",
    "\n",
    "    else:\n",
    "        if line.strip()[0:16] != \"\\\\begin{Verbatim}\":\n",
    "            f.write(line)\n",
    "        else:\n",
    "            tog = 1\n",
    "\n",
    "# At the end, close the file again.\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '\\\\begin{Verbatim}[commandchars=\\\\\\\\\\\\{\\\\}]\\n', '{\\\\color{outcolor}Out[{\\\\color{outcolor}53}]:} <matplotlib.image.AxesImage at 0x208d846f898>\\n', '\\\\end{Verbatim}\\n', '            \\n', '    \\\\begin{center}\\n', '    \\\\adjustimage{max size={0.9\\\\linewidth}{0.9\\\\paperheight}}{draft_for_paper_files/draft_for_paper_98_1.png}\\n', '    \\\\end{center}\\n', '    { \\\\hspace*{\\\\fill} \\\\\\\\}\\n', '    \\n', '    \\\\begin{Verbatim}[commandchars=\\\\\\\\\\\\{\\\\}]\\n', '{\\\\color{incolor}In [{\\\\color{incolor}57}]:} \\\\PY{n}{plt}\\\\PY{o}{.}\\\\PY{n}{imshow}\\\\PY{p}{(}\\\\PY{n}{np}\\\\PY{o}{.}\\\\PY{n}{reshape}\\\\PY{p}{(}\\\\PY{n}{M}\\\\PY{p}{[}\\\\PY{p}{:}\\\\PY{p}{,}\\\\PY{l+m+mi}{4}\\\\PY{p}{]}\\\\PY{p}{,} \\\\PY{p}{(}\\\\PY{l+m+mi}{20}\\\\PY{p}{,}\\\\PY{l+m+mi}{68}\\\\PY{p}{)}\\\\PY{p}{,} \\\\PY{n}{order}\\\\PY{o}{=}\\\\PY{l+s+s2}{\\\\PYZdq{}}\\\\PY{l+s+s2}{F}\\\\PY{l+s+s2}{\\\\PYZdq{}}\\\\PY{p}{)}\\\\PY{p}{)}\\n', '\\\\end{Verbatim}\\n']\n"
     ]
    }
   ],
   "source": [
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
